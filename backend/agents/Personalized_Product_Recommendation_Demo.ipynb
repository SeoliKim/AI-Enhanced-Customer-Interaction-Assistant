{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79a7e50-47a9-4dee-a3c6-80309ef1f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Found existing installation: numpy 1.26.0\n",
      "Uninstalling numpy-1.26.0:\n",
      "  Successfully uninstalled numpy-1.26.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.0\n",
      "  Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (53 kB)\n",
      "Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tableone 0.9.1 requires openpyxl>=3.1.2, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n",
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --yes\n",
      "Requirement already satisfied: gensim in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "!pip install scikit-learn \n",
    "!pip uninstall numpy --yes \n",
    "!pip install numpy==1.26.0 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score \n",
    "!pip install gensim --yes \n",
    "!pip install gensim \n",
    "import gensim \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import time \n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f721128-d8b7-44f9-bd6b-595e1d559720",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/jocelyn/Desktop/DXC-4 Technology /AI-Enhanced-Customer-Interaction-Assistant/data/Final_db.csv\" \n",
    "df = pd.read_csv(filename, header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b50269f-46a8-4f21-8168-995451dc647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.23845749,  0.3624568 , -0.12827969, -0.0203971 , -0.08743068,\n",
      "       -0.60392404,  0.09586775,  1.0121382 , -0.9376453 , -0.8946931 ,\n",
      "       -0.1117814 , -0.39599237,  0.2438666 , -0.02225464,  0.11475515,\n",
      "       -0.23194876,  0.38611358, -0.38105744, -0.24385457, -0.9080621 ,\n",
      "        0.34592336, -0.40780562,  0.7255114 , -0.19838431, -0.343826  ,\n",
      "        0.48263535, -0.5869364 , -0.504926  , -0.3590857 ,  0.23004445,\n",
      "        0.42767516,  0.12268541, -0.03665828, -0.6182512 , -0.20388743,\n",
      "        0.3533885 , -0.37944192,  0.04555244,  0.0794154 , -0.60836005,\n",
      "       -0.16062722,  0.02007657,  0.67855823, -0.08166214,  0.45723885,\n",
      "       -0.22539373,  0.16015929, -0.05988402,  0.8043581 ,  0.37596533,\n",
      "        0.01472783,  0.26061082, -0.54752105, -0.3700534 , -0.19197458,\n",
      "        0.16850606,  0.10682013,  0.06305631, -0.54911214, -0.09295835,\n",
      "        0.12988031,  0.3429099 ,  0.10689566,  0.71437883, -0.05957205,\n",
      "        0.611774  ,  0.28905827,  0.6063857 , -0.73110735,  0.22976363,\n",
      "        0.0837542 ,  0.6076691 ,  0.5539197 ,  0.11803462,  0.8098934 ,\n",
      "       -0.2891233 , -0.0446466 ,  0.31019637,  0.18752736,  0.02872138,\n",
      "       -0.14827693, -0.17363428, -0.49317342,  0.35012823, -0.34986863,\n",
      "       -0.59627926,  0.2934213 ,  0.81076777,  0.5455295 ,  0.01747569,\n",
      "        0.09590697,  0.43518305,  0.01284422, -0.1971799 ,  0.42113972,\n",
      "       -0.16773987, -0.01530361, -0.38843903,  0.17501467, -0.25006205],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.37508813,  0.15598683, -0.23246305, -0.36015102,  0.18118416,\n",
      "       -0.6896268 , -0.1055095 ,  0.80005836, -0.3997363 ,  0.5488454 ,\n",
      "       -0.13774063, -0.7263208 ,  0.36485866,  0.36753452,  0.34609443,\n",
      "       -0.72409916,  0.0120067 , -0.26713473,  0.48139066, -0.6848167 ,\n",
      "       -0.21496667, -0.00119303, -0.05488531, -0.26409936, -0.47101307,\n",
      "        0.9784376 , -0.1727949 , -0.7435304 , -0.32528225,  0.00164112,\n",
      "        0.35210112,  0.02003151,  0.63009876,  0.05098092, -0.20794235,\n",
      "        0.18066151,  0.21402279, -0.32042664, -0.2494404 , -0.87374127,\n",
      "       -0.07704333, -0.6734596 , -0.2501176 ,  0.34295583, -0.03244174,\n",
      "       -0.49638602, -0.4266417 , -0.16720447,  0.09600978, -0.32421634,\n",
      "        0.28516   , -0.33968607,  0.35983568,  0.17740777,  0.01335808,\n",
      "        0.16842346, -0.32462013, -0.14579533, -0.7261677 ,  0.29834312,\n",
      "        0.49702042, -0.37153724,  0.09700619,  0.5618355 , -0.7344726 ,\n",
      "        0.5118353 , -0.2652746 , -0.10986418, -1.1227125 ,  0.811813  ,\n",
      "       -1.0099032 ,  0.44842052,  0.7704168 , -0.6729953 ,  0.04481961,\n",
      "        0.5005529 , -0.4224979 ,  0.30302125, -0.64894354, -0.13110717,\n",
      "        0.0602228 ,  0.27207994, -0.9528338 ,  0.28016424, -0.4046446 ,\n",
      "        0.06539208,  0.09574389,  0.99246687, -0.08773593, -0.16945726,\n",
      "        0.7486877 , -0.00476863,  0.39975318,  0.5062374 ,  0.6243582 ,\n",
      "        0.0090649 , -0.25576052,  0.13130465,  0.31200168, -0.0688473 ],\n",
      "      dtype=float32), array([-4.3820545e-01,  3.0999547e-01,  2.4411151e-02, -3.0531367e-02,\n",
      "        3.0269149e-01, -8.2911307e-01,  3.0948353e-01,  5.0771934e-01,\n",
      "       -5.2753192e-01,  4.0038336e-02,  1.8558414e-01,  1.4943694e-01,\n",
      "        5.0817680e-01, -2.7699804e-02,  5.2262610e-01, -2.6022577e-01,\n",
      "        7.1507525e-01, -2.5001189e-01, -3.5643598e-01, -1.5816336e+00,\n",
      "        4.7636721e-01, -1.2767224e-01,  7.8834969e-01,  1.4286336e-01,\n",
      "       -4.6037814e-01,  4.4482422e-01, -1.2715079e-01, -2.2971673e-01,\n",
      "       -1.5099037e-01,  4.5091784e-01,  7.2507173e-01,  5.0316644e-01,\n",
      "        1.6724582e-01, -2.9940370e-01, -2.4375014e-01,  6.3551265e-01,\n",
      "       -1.2846425e-01, -5.4918569e-01, -7.8710049e-01, -8.3763194e-01,\n",
      "        5.2570319e-01, -5.2729917e-01,  9.9454117e-01,  2.7214098e-01,\n",
      "        5.6158030e-01,  9.1591991e-02, -9.2187084e-02, -3.5565856e-01,\n",
      "        4.6210945e-01, -2.1824498e-01,  8.3372498e-01, -5.3918248e-01,\n",
      "       -3.5007945e-01, -7.4065298e-02, -8.7238544e-01, -3.1307641e-01,\n",
      "       -3.2698417e-01,  3.0272520e-01, -6.9708180e-01,  1.6911392e-01,\n",
      "        2.0658767e-01,  1.8026511e-01,  5.2973509e-01,  1.3682301e-01,\n",
      "       -3.5154048e-02,  4.0021351e-01,  9.5979832e-02,  7.8149056e-01,\n",
      "       -9.6061349e-01,  5.2980769e-02, -3.1865263e-01,  5.4773211e-01,\n",
      "       -5.6571230e-02,  5.1980817e-01,  1.0481068e+00,  9.6564591e-03,\n",
      "        7.5177684e-02,  9.8065645e-01, -4.6235681e-01,  3.7377134e-01,\n",
      "       -1.2204945e-01,  3.7083289e-01, -7.7445143e-01,  5.0965184e-01,\n",
      "       -4.8194328e-04, -3.1843376e-01,  5.1131380e-01,  1.1146522e+00,\n",
      "        2.4219024e-01, -2.9020953e-01,  1.5311016e+00,  4.2677569e-01,\n",
      "        7.2322465e-02,  2.3342025e-01,  7.2904223e-01, -5.4155272e-02,\n",
      "        7.5122404e-01, -5.3352910e-01, -6.3705236e-01,  2.8589851e-01],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.5869195 ,  0.38884076, -0.01678901,  0.6996224 , -0.423335  ,\n",
      "       -0.17511529, -0.36892116,  1.0985333 , -0.5558066 , -0.86902046,\n",
      "       -0.18746565, -0.7232391 ,  0.06982411,  0.44153193,  0.23816597,\n",
      "       -0.3752111 ,  0.57660943, -0.37844968,  0.45629016, -0.90514207,\n",
      "       -0.6335549 , -0.11180807, -0.05673438,  0.00833666, -0.530267  ,\n",
      "       -0.95797586, -1.0036689 , -0.29245564, -0.49260008,  0.3046161 ,\n",
      "        0.82088137, -0.09702808, -0.72485405, -0.18684322, -0.42000306,\n",
      "        0.43426517, -0.08655129, -0.08239555,  0.30427304, -0.5234642 ,\n",
      "        0.273943  ,  0.03157973, -0.3085732 , -0.31391713,  0.7168488 ,\n",
      "        0.17033303,  0.4098473 ,  0.1781364 ,  1.0384172 ,  0.33774033,\n",
      "        0.2502832 , -0.5018258 , -0.36273885,  0.40395698,  0.18836407,\n",
      "        1.1229092 ,  0.6640435 ,  0.07099851, -0.45100304,  0.40457824,\n",
      "       -0.6128741 ,  0.93572825, -0.5750944 , -0.35689083,  0.1584325 ,\n",
      "       -0.61683166, -0.04952087, -0.08877612, -1.0649639 , -0.00150762,\n",
      "        0.45781848,  0.65104795,  1.1369209 ,  0.23747128,  0.6632351 ,\n",
      "        0.05845628, -0.18425715, -0.49475977, -0.5699939 , -0.09774822,\n",
      "       -0.25946617, -0.6426093 , -0.00684279,  1.0891129 , -0.2473344 ,\n",
      "       -0.32913327, -0.37927735,  1.4102958 ,  1.1208366 ,  1.0956875 ,\n",
      "        0.73115855,  0.8547178 , -0.25878584,  0.97398514,  0.675543  ,\n",
      "        0.904263  ,  0.18869041,  0.12632051,  0.10759274, -0.28810182],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# check to see if there are products with multiple orders \n",
    "product_id_value_counts = df[\"product_id\"].value_counts() \n",
    "\n",
    "# store the products with multiple orders in products_multiple_orders \n",
    "products_multiple_orders = product_id_value_counts[product_id_value_counts > 1] \n",
    "\n",
    "# create a new column in df that stores the number of times each item was purchased \n",
    "df[\"times_purchased\"] = df[\"product_id\"].map(product_id_value_counts) \n",
    "\n",
    "# stores all of the unique product categories into the array \"product_categories\" \n",
    "product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "\n",
    "# fill in rows in df[\"review_comment_title\"] column that have na values with \"\" \n",
    "df[\"review_comment_title\"] = df[\"review_comment_title\"].fillna(\"\") \n",
    "\n",
    "# fill in rows in df[\"review_comment_message\"] column that have na values with \"\" \n",
    "df[\"review_comment_message\"] = df[\"review_comment_message\"].fillna(\"\") \n",
    "\n",
    "# merge the product reviews and product review titles with a space in between both \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"review_comment_message\"] + \" \" + df[\"review_comment_title\"] \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"merged_review_messages_and_titles\"].str.strip() \n",
    "\n",
    "# dictionary to store dataframes of the product reviews for all products in each category \n",
    "# products are separated by category \n",
    "product_reviews_by_category = {}; \n",
    "\n",
    "# fill in dictionary with keys (df category) and values (product_id and product reviews for all products in that category) \n",
    "for category in product_categories: \n",
    "    product_reviews_by_category[\"df_\" + str(category)] = df[df[\"product_cat_name_translated\"] == category][[\"product_id\", \"merged_review_messages_and_titles\"]] \n",
    "\n",
    "# feature ~ product title and review \n",
    "X = df[\"merged_review_messages_and_titles\"] \n",
    "\n",
    "# label ~ product category \n",
    "y = df[\"product_cat_name_translated\"] \n",
    "\n",
    "# preprocess each (each row) product title and review \n",
    "X = X.apply(lambda row: gensim.utils.simple_preprocess(row)) \n",
    "\n",
    "# split data into a training set and a test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=1111) \n",
    "\n",
    "word2vec_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=1) \n",
    "\n",
    "# replace every word in the dataset that's also found in word2vec_model with their word embedding \n",
    "# a set with all of the unique words in the word2vex_model \n",
    "words = set(word2vec_model.wv.index_to_key) \n",
    "\n",
    "# X_train word embeddings \n",
    "# array for all of the word embeddings for X_train \n",
    "X_train_word_embeddings = []; \n",
    "for row in X_train: \n",
    "    row_embedding = [] \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_train_word_embeddings.append(np.array(row_embedding)) \n",
    "\n",
    "# X_test word embeddings \n",
    "# array for all of the word embeddings for X_test \n",
    "X_test_word_embeddings = []; \n",
    "for row in X_test: \n",
    "    row_embedding = []; \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_test_word_embeddings.append(np.array(row_embedding)) \n",
    "\n",
    "X_train_feature_vector = []\n",
    "for w in X_train_word_embeddings:\n",
    "    if w.size:\n",
    "        X_train_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_train_feature_vector.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_feature_vector = []\n",
    "for w in X_test_word_embeddings:\n",
    "    if w.size:\n",
    "        X_test_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_test_feature_vector.append(np.zeros(100, dtype=float))\n",
    "\n",
    "print(X_train_feature_vector[1:11]) \n",
    "\n",
    "# logistic regression \n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_feature_vector, y_train)\n",
    "\n",
    "probability_predictions = model.predict_proba(X_test_feature_vector) \n",
    "\n",
    "# predict most likely product category \n",
    "class_label_predictions = model.predict(X_test_feature_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6d0b3-1f51-4691-9b13-32ca5ffb6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello! Welcome to the personalized product recommendation chatbot.\") \n",
    "\n",
    "# create a list containing the vectors for the tokens/words found in the user input that are also found in the dataset of available products \n",
    "token_vectors = [] \n",
    "\n",
    "while len(token_vectors) == 0: \n",
    "    another = \"\"\n",
    "    user_input = input(\"\\nWhat product are you looking for?\") \n",
    "\n",
    "    print(\"Generating response ...\") \n",
    "\n",
    "    user_input_tokens = list(gensim.utils.simple_preprocess(user_input)) \n",
    "    token_vectors = [] \n",
    "    \n",
    "    # loop through all tokens from the tokenized version of the user input \n",
    "    for token in user_input_tokens: \n",
    "        # if the token is also found in the dataset \n",
    "        if token in word2vec_model.wv.key_to_index: \n",
    "            # add its word vector to the \"token_vectors\" list \n",
    "            token_vectors.append(word2vec_model.wv[token]) \n",
    "\n",
    "    # if there are vectors \n",
    "    if len(token_vectors) > 0: \n",
    "        # calculate the mean for each token_vector and combine into an array \n",
    "        overall_token_vector = np.mean(token_vectors, axis=0) \n",
    "        # reshape into a two dimensional array \n",
    "        overall_token_vector = overall_token_vector.reshape(1, -1) \n",
    "        word2vec_prediction = model.predict(overall_token_vector) \n",
    "    \n",
    "    else: \n",
    "        user_input = input(\"\\nWe can't find a related product. Please input more detail.\") \n",
    "\n",
    "    word2vec_prediction_str = \"df_\" + str(word2vec_prediction[0]) \n",
    "    \n",
    "    #vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "    \n",
    "    product_reviews_by_category[word2vec_prediction_str] \n",
    "    \n",
    "    # use bigrams (for cases of negation like \"not good\") and trigrams (for cases with numbers like \"bought 3 pairs\") \n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "    \n",
    "    # fit vectorizer to the product review titles and messages \n",
    "    vectorizer.fit(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "    \n",
    "    # result_matrix contains each document's TF_IDF scores \n",
    "    resulting_matrix = vectorizer.transform(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "        \n",
    "    product_id = product_reviews_by_category[word2vec_prediction_str][\"product_id\"].tolist() \n",
    "        \n",
    "    resulting_matrix = pd.DataFrame(resulting_matrix.toarray(), index=product_id, columns=vectorizer.get_feature_names_out()) \n",
    "    \n",
    "    # determine product in category that's most similar to user input \n",
    "    user_input_TF_IDF_vector = vectorizer.transform([user_input]) \n",
    "    # similarity of user input word vector and each of the rows' word vectors \n",
    "    similarity = cosine_similarity(user_input_TF_IDF_vector, resulting_matrix) \n",
    "    greatest_similarity_indices = np.argsort(similarity[0][::-1]) \n",
    "    greatest_similarity_product_ids = resulting_matrix.index[greatest_similarity_indices] \n",
    "    greatest_similarity_product_ids_list = greatest_similarity_product_ids.unique().tolist() \n",
    "    \n",
    "    # rows with that product id \n",
    "    products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[0]] \n",
    "    \n",
    "    clear_output(wait=True) \n",
    "    \n",
    "    print(\"\\nHow about this product?\") \n",
    "    print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "    print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "    print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "    more_detail_user_input = input(\"\\nDo you want more detail about this product? (Y/N)\") \n",
    "    \n",
    "    more_detail_user_input = more_detail_user_input.upper().strip() \n",
    "    \n",
    "    more_recommendations = \"N\" \n",
    "    more_detail = \"\" \n",
    "    moree = False \n",
    "    user_input_product_cat = \"\" \n",
    "    user_input = \"\" \n",
    "    \n",
    "    if more_detail_user_input == \"Y\": \n",
    "        print(\"\\nOk. Here is more detail about the product.\") \n",
    "        print(\"Total Orders: \", len(products_df)) \n",
    "        print(\"Product Weight (g): \", products_df[\"product_weight_g\"].iloc[0]) \n",
    "        print(\"Product Length (cm): \", products_df[\"product_length_cm\"].iloc[0]) \n",
    "        print(\"Product Height (cm): \", products_df[\"product_height_cm\"].iloc[0]) \n",
    "        print(\"Product Width (cm): \", products_df[\"product_width_cm\"].iloc[0]) \n",
    "        \n",
    "        good = input(\"\\nIs this a good recommendation? (Y/N)\") \n",
    "        good = good.upper().strip() \n",
    "    \n",
    "        if good == \"Y\": \n",
    "            another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "            another = another.upper().strip() \n",
    "            \n",
    "            if another == \"Y\": \n",
    "                token_vectors = []; \n",
    "            else: \n",
    "                print(\"\\nHave a great day! :)\") \n",
    "                break \n",
    "        \n",
    "        else: \n",
    "            print(\"\\nWe're sorry.\") \n",
    "            token_vectors = []; \n",
    "    \n",
    "    else: \n",
    "        more_recommendations = input(\"\\nWould you like more similar product recommendations? (Y/N)\") \n",
    "        more_recommendations = more_recommendations.upper().strip() \n",
    "    \n",
    "    if more_recommendations == \"Y\": \n",
    "        print(\"\\nOk. Here are some more product recommendations.\") \n",
    "        if (len(greatest_similarity_product_ids_list) == 3) | (len(greatest_similarity_product_ids_list) > 3): \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "        \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[2]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "            good = input(\"\\nWere any of these recommendations helpful? (Y/N)\") \n",
    "            good = good.upper().strip() \n",
    "    \n",
    "            if good == \"Y\": \n",
    "                another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "                another = another.upper().strip() \n",
    "                \n",
    "                if another == \"Y\": \n",
    "                    token_vectors = []; \n",
    "                else: \n",
    "                    print(\"\\nHave a great day! :)\") \n",
    "                    break \n",
    "            \n",
    "            else: \n",
    "                token_vectors = []; \n",
    "                print(\"\\nWe're sorry.\") \n",
    "    \n",
    "        elif len(greatest_similarity_product_ids_list) == 2: \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "        \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "            good = input(\"\\nWere any of these recommendations helpful? (Y/N)\") \n",
    "            good = good.upper().strip() \n",
    "    \n",
    "            if good == \"Y\": \n",
    "                another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "                another = another.upper().strip() \n",
    "                \n",
    "                if another == \"Y\": \n",
    "                    token_vectors = []; \n",
    "                else: \n",
    "                    print(\"\\nHave a great day! :)\") \n",
    "                    break \n",
    "            \n",
    "            else: \n",
    "                token_vectors = []; \n",
    "                print(\"\\nWe're sorry.\") \n",
    "    \n",
    "        else: \n",
    "            moree = True \n",
    "            \n",
    "            more_detail = input(\"\\nThere are no more similar products. What category is your product in? Enter number.\") \n",
    "    \n",
    "            # a dictionary with a number associated with each product category \n",
    "            product_categories_dict = {} \n",
    "        \n",
    "            # array with unique product categories \n",
    "            product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "        \n",
    "            for i in range(len(product_categories)): \n",
    "                product_categories_dict[i+1] = product_categories[i] \n",
    "        \n",
    "            # ask user for product category \n",
    "            print(\"\\nWhich category is the product in? Enter in number.\") \n",
    "            for keys, values in product_categories_dict.items(): \n",
    "                print(f\"{keys}: {values}\") \n",
    "            \n",
    "            user_input_2 = input(\"\") \n",
    "            \n",
    "            user_input_2 = int(user_input_2.strip()) \n",
    "            \n",
    "            user_input_product_cat = product_categories_dict.get(user_input_2) \n",
    "\n",
    "    else: \n",
    "        if (more_detail_user_input != \"Y\") & (another != \"Y\"): \n",
    "            print(\"\\nHave a great day! :)\") \n",
    "            break \n",
    "    \n",
    "    if moree == True: \n",
    "        user_product_category = df[df[\"product_cat_name_translated\"] == user_input_product_cat] \n",
    "        ranked_products = user_product_category.sort_values(by=\"review_score\", ascending=False) \n",
    "        \n",
    "        print(\"\\nHere are the three highest ranked products in that category.\") \n",
    "        print(ranked_products.head(3)[\"product_id\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58087f4-0812-4718-960f-0a0c20c58431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
