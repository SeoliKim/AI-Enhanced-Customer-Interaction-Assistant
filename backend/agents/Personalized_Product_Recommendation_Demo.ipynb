{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79a7e50-47a9-4dee-a3c6-80309ef1f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Found existing installation: numpy 1.26.0\n",
      "Uninstalling numpy-1.26.0:\n",
      "  Successfully uninstalled numpy-1.26.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.0\n",
      "  Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (53 kB)\n",
      "Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tableone 0.9.1 requires openpyxl>=3.1.2, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n",
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --yes\n",
      "Requirement already satisfied: gensim in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "!pip install scikit-learn \n",
    "!pip uninstall numpy --yes \n",
    "!pip install numpy==1.26.0 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score \n",
    "!pip install gensim --yes \n",
    "!pip install gensim \n",
    "import gensim \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import time \n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f721128-d8b7-44f9-bd6b-595e1d559720",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/jocelyn/Desktop/DXC-4 Technology /AI-Enhanced-Customer-Interaction-Assistant/data/Final_db.csv\" \n",
    "df = pd.read_csv(filename, header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b50269f-46a8-4f21-8168-995451dc647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([ 0.05354221,  0.13208275, -0.16940065,  0.05665206, -0.16508731,\n",
      "       -0.3541201 ,  0.09052593,  0.890001  , -0.96438485, -0.66019213,\n",
      "       -0.15792556, -0.24152727,  0.14840783,  0.12257266,  0.2360309 ,\n",
      "       -0.46138272,  0.42896372, -0.18693131, -0.13388953, -1.0141027 ,\n",
      "        0.01795853, -0.51663244,  0.60366553, -0.02277351, -0.3970582 ,\n",
      "        0.4929138 , -0.55515164, -0.53188825, -0.28728962,  0.45481157,\n",
      "        0.24500136, -0.022601  , -0.16812837, -0.4638587 , -0.23465165,\n",
      "        0.24191125, -0.39878955,  0.08149692,  0.1741691 , -0.99229354,\n",
      "       -0.12039705, -0.15553316,  0.5733589 , -0.03359653,  0.43569508,\n",
      "       -0.09287097,  0.3271199 , -0.00987546,  0.7061674 ,  0.2620357 ,\n",
      "       -0.02264457,  0.29864785, -0.44106922, -0.38840866, -0.127857  ,\n",
      "        0.03752612,  0.18235971,  0.17443117, -0.58801675, -0.03161876,\n",
      "        0.08682609,  0.27275062,  0.03446628,  0.7965225 , -0.14401759,\n",
      "        0.6863199 ,  0.17751595,  0.6098091 , -0.7147522 ,  0.08342588,\n",
      "        0.16161016,  0.5742132 ,  0.47288197,  0.18740903,  0.80990505,\n",
      "       -0.17332447, -0.07397684,  0.42499465,  0.3410832 , -0.03010669,\n",
      "        0.05968844, -0.1164849 , -0.50483924,  0.26088676, -0.2766548 ,\n",
      "       -0.6143581 ,  0.41108862,  0.94473124,  0.6542181 ,  0.02559659,\n",
      "        0.44444662,  0.51587486, -0.02198762, -0.19093902,  0.90682906,\n",
      "       -0.02949069,  0.17034766, -0.5998371 ,  0.32033697, -0.48051196],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.4784547 ,  0.05350556, -0.38826212, -0.3085643 ,  0.47122383,\n",
      "       -0.5034266 , -0.186679  ,  0.84066004, -0.45800126,  0.54843324,\n",
      "        0.0739336 , -0.86963713,  0.34771767,  0.4775854 ,  0.3625041 ,\n",
      "       -0.7810435 , -0.05623232, -0.23668855,  0.4846661 , -0.6363085 ,\n",
      "       -0.12959266,  0.07798502,  0.08697101, -0.3035953 , -0.3597442 ,\n",
      "        0.81427246, -0.0686657 , -0.7565447 , -0.3446345 ,  0.07560143,\n",
      "        0.76269245,  0.10349053,  0.59903663, -0.27418947, -0.2840621 ,\n",
      "        0.5456628 ,  0.31031197, -0.5767074 , -0.3394937 , -1.1298594 ,\n",
      "       -0.02519982, -0.6702542 , -0.19414605,  0.28612342, -0.13718067,\n",
      "       -0.31899118, -0.19426781, -0.19498844, -0.04603671, -0.393082  ,\n",
      "        0.3366799 , -0.15083621,  0.42990446,  0.28428382,  0.35499024,\n",
      "        0.0459954 , -0.219769  , -0.2054896 , -0.6996634 ,  0.27364248,\n",
      "        0.4321655 , -0.36560902, -0.03855875,  0.6066367 , -0.8214594 ,\n",
      "        0.11558827, -0.25056553, -0.02511089, -1.0235615 ,  0.7929014 ,\n",
      "       -0.93392456,  0.40057746,  0.82166547, -0.8327515 , -0.02290226,\n",
      "        0.30776262, -0.5026401 ,  0.29266387, -0.7305708 ,  0.16626343,\n",
      "        0.07956365,  0.16021477, -0.82411593,  0.22717941, -0.27921018,\n",
      "        0.10087761,  0.03632913,  0.6076159 , -0.09558721, -0.01293566,\n",
      "        0.56695706,  0.0598427 ,  0.4240049 ,  0.40714157,  0.726781  ,\n",
      "        0.05809618, -0.19264102,  0.10254119,  0.51626116, -0.18587583],\n",
      "      dtype=float32), array([-5.09789646e-01,  4.88987446e-01,  1.25599265e-01, -6.50973246e-02,\n",
      "        2.73795694e-01, -9.13708627e-01,  4.43981439e-01,  7.99504578e-01,\n",
      "       -6.03839457e-01, -3.66926845e-03,  7.33622089e-02,  1.28055155e-01,\n",
      "        4.38224673e-01, -1.22585833e-01,  6.01834834e-01, -3.03474247e-01,\n",
      "        6.74542129e-01, -3.12604070e-01, -2.75223792e-01, -1.47678864e+00,\n",
      "        4.37769324e-01, -1.19953357e-01,  7.42162228e-01, -1.27998605e-01,\n",
      "       -6.90936148e-01,  4.60228056e-01, -5.27277172e-01, -2.59723753e-01,\n",
      "       -2.71575302e-01,  4.97936010e-01,  9.21452940e-01,  4.09144402e-01,\n",
      "        5.11596978e-01, -5.55127978e-01, -3.11209291e-01,  1.05539024e+00,\n",
      "       -2.26685092e-01, -8.22512805e-01, -7.22057521e-01, -1.09361756e+00,\n",
      "        6.12043917e-01, -1.11647499e+00,  7.85058200e-01,  3.29471678e-01,\n",
      "        7.32010186e-01, -1.07815683e-01, -3.39926332e-01, -3.86686713e-01,\n",
      "        5.81220329e-01,  1.77380629e-02,  7.48649180e-01, -4.33762819e-01,\n",
      "       -2.11317107e-01, -6.49121415e-04, -7.72279263e-01, -3.94726366e-01,\n",
      "       -2.62909561e-01,  4.41075653e-01, -7.22740829e-01,  2.33312547e-01,\n",
      "        1.18400194e-01,  2.89532542e-03,  3.12965512e-01, -5.20218797e-02,\n",
      "        2.17594206e-04,  2.97877938e-01,  1.55467227e-01,  7.49128878e-01,\n",
      "       -6.50245011e-01, -2.12692115e-02, -2.50287652e-01,  4.98090178e-01,\n",
      "        2.08621640e-02,  4.52481478e-01,  9.48169172e-01,  1.24242574e-01,\n",
      "        7.44580105e-02,  8.23644340e-01, -4.83001500e-01,  2.28631094e-01,\n",
      "       -4.25938852e-02,  5.15861034e-01, -6.60683990e-01,  4.56523269e-01,\n",
      "        2.22519875e-01, -3.06480050e-01,  5.35878658e-01,  8.32571924e-01,\n",
      "        1.19113624e-01, -4.15732294e-01,  1.11096323e+00,  2.97141790e-01,\n",
      "        4.56011705e-02,  3.35196137e-01,  2.83397049e-01, -2.99577504e-01,\n",
      "        6.20208442e-01, -2.29757294e-01, -4.39909458e-01,  1.68072417e-01],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.829457  ,  0.4987924 ,  0.07017484,  0.78682476, -0.42810336,\n",
      "       -0.6480039 , -0.10471839,  1.7497697 , -0.80378866, -0.8364601 ,\n",
      "       -0.32650614, -0.79641944,  0.2994912 ,  0.28568316,  0.46231422,\n",
      "       -0.46037063,  0.6287727 , -0.48591506,  0.5317502 , -1.1819019 ,\n",
      "       -0.48449484, -0.17030643, -0.06657835, -0.05342617, -0.38607356,\n",
      "       -0.8530116 , -0.9171657 , -0.23356676, -0.3990256 ,  0.0812228 ,\n",
      "        0.64710814,  0.13420133, -0.84407353, -0.10625213, -0.19617891,\n",
      "        0.3084872 ,  0.0096767 , -0.04163675,  0.30813655, -0.40215072,\n",
      "        0.08334449, -0.05291267, -0.3867276 , -0.26663214,  0.829717  ,\n",
      "        0.3300459 ,  0.2734519 ,  0.25704876,  0.9244523 ,  0.39707637,\n",
      "        0.17425661, -0.3817955 , -0.5251914 ,  0.39310038,  0.25259116,\n",
      "        1.0252453 ,  0.5022836 ,  0.29534864, -0.57096004,  0.41291282,\n",
      "       -0.46848544,  1.1455362 , -0.5251822 , -0.48269853,  0.45796832,\n",
      "       -0.7331677 ,  0.09359291, -0.14788489, -0.7702768 , -0.02143671,\n",
      "        0.53552175,  0.48662758,  0.862856  ,  0.27159926,  0.6573459 ,\n",
      "       -0.11470868, -0.12414966, -0.42764488, -0.33892813, -0.04081262,\n",
      "       -0.3345163 , -0.5851868 ,  0.03966489,  0.68653256, -0.3130223 ,\n",
      "       -0.35956326, -0.4094936 ,  1.3176135 ,  1.0152264 ,  0.74263376,\n",
      "        0.50955003,  0.9210231 , -0.06077866,  1.0037993 ,  0.6981244 ,\n",
      "        0.80384856,  0.03239767,  0.06233177, -0.17164636, -0.2664395 ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# check to see if there are products with multiple orders \n",
    "product_id_value_counts = df[\"product_id\"].value_counts() \n",
    "\n",
    "# store the products with multiple orders in products_multiple_orders \n",
    "products_multiple_orders = product_id_value_counts[product_id_value_counts > 1] \n",
    "\n",
    "# create a new column in df that stores the number of times each item was purchased \n",
    "df[\"times_purchased\"] = df[\"product_id\"].map(product_id_value_counts) \n",
    "\n",
    "# stores all of the unique product categories into the array \"product_categories\" \n",
    "product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "\n",
    "# fill in rows in df[\"review_comment_title\"] column that have na values with \"\" \n",
    "df[\"review_comment_title\"] = df[\"review_comment_title\"].fillna(\"\") \n",
    "\n",
    "# fill in rows in df[\"review_comment_message\"] column that have na values with \"\" \n",
    "df[\"review_comment_message\"] = df[\"review_comment_message\"].fillna(\"\") \n",
    "\n",
    "# merge the product reviews and product review titles with a space in between both \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"review_comment_message\"] + \" \" + df[\"review_comment_title\"] \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"merged_review_messages_and_titles\"].str.strip() \n",
    "\n",
    "# dictionary to store dataframes of the product reviews for all products in each category \n",
    "# products are separated by category \n",
    "product_reviews_by_category = {}; \n",
    "\n",
    "# fill in dictionary with keys (df category) and values (product_id and product reviews for all products in that category) \n",
    "for category in product_categories: \n",
    "    product_reviews_by_category[\"df_\" + str(category)] = df[df[\"product_cat_name_translated\"] == category][[\"product_id\", \"merged_review_messages_and_titles\"]] \n",
    "\n",
    "# feature ~ product title and review \n",
    "X = df[\"merged_review_messages_and_titles\"] \n",
    "\n",
    "# label ~ product category \n",
    "y = df[\"product_cat_name_translated\"] \n",
    "\n",
    "# preprocess each (each row) product title and review \n",
    "X = X.apply(lambda row: gensim.utils.simple_preprocess(row)) \n",
    "\n",
    "# split data into a training set and a test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=1111) \n",
    "\n",
    "word2vec_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=1) \n",
    "\n",
    "# replace every word in the dataset that's also found in word2vec_model with their word embedding \n",
    "# a set with all of the unique words in the word2vex_model \n",
    "words = set(word2vec_model.wv.index_to_key) \n",
    "\n",
    "# X_train word embeddings \n",
    "# array for all of the word embeddings for X_train \n",
    "X_train_word_embeddings = []; \n",
    "for row in X_train: \n",
    "    row_embedding = [] \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_train_word_embeddings.append(np.array(row_embedding)) \n",
    "\n",
    "# X_test word embeddings \n",
    "# array for all of the word embeddings for X_test \n",
    "X_test_word_embeddings = []; \n",
    "for row in X_test: \n",
    "    row_embedding = []; \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_test_word_embeddings.append(np.array(row_embedding)) \n",
    "\n",
    "X_train_feature_vector = []\n",
    "for w in X_train_word_embeddings:\n",
    "    if w.size:\n",
    "        X_train_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_train_feature_vector.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_feature_vector = []\n",
    "for w in X_test_word_embeddings:\n",
    "    if w.size:\n",
    "        X_test_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_test_feature_vector.append(np.zeros(100, dtype=float))\n",
    "\n",
    "print(X_train_feature_vector[1:11]) \n",
    "\n",
    "# logistic regression \n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_feature_vector, y_train)\n",
    "\n",
    "probability_predictions = model.predict_proba(X_test_feature_vector) \n",
    "\n",
    "# predict most likely product category \n",
    "class_label_predictions = model.predict(X_test_feature_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7348679-919e-4fe6-a373-3205cafaebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6d0b3-1f51-4691-9b13-32ca5ffb6e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome to the personalized product recommendation chatbot.\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello! Welcome to the personalized product recommendation chatbot.\") \n",
    "\n",
    "# create a list containing the vectors for the tokens/words found in the user input that are also found in the dataset of available products \n",
    "token_vectors = [] \n",
    "\n",
    "while len(token_vectors) == 0: \n",
    "    user_input = input(\"\\nWhat product are you looking for?\") \n",
    "\n",
    "    print(\"Generating response ...\") \n",
    "\n",
    "    user_input_tokens = list(gensim.utils.simple_preprocess(user_input)) \n",
    "    token_vectors = [] \n",
    "    \n",
    "    # loop through all tokens from the tokenized version of the user input \n",
    "    for token in user_input_tokens: \n",
    "        # if the token is also found in the dataset \n",
    "        if token in word2vec_model.wv.key_to_index: \n",
    "            # add its word vector to the \"token_vectors\" list \n",
    "            token_vectors.append(word2vec_model.wv[token]) \n",
    "\n",
    "    # if there are vectors \n",
    "    if len(token_vectors) > 0: \n",
    "        # calculate the mean for each token_vector and combine into an array \n",
    "        overall_token_vector = np.mean(token_vectors, axis=0) \n",
    "        # reshape into a two dimensional array \n",
    "        overall_token_vector = overall_token_vector.reshape(1, -1) \n",
    "        word2vec_prediction = model.predict(overall_token_vector) \n",
    "    \n",
    "    else: \n",
    "        user_input = input(\"\\nWe can't find a related product. Please input more detail.\") \n",
    "\n",
    "    word2vec_prediction_str = \"df_\" + str(word2vec_prediction[0]) \n",
    "    \n",
    "    #vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "    \n",
    "    product_reviews_by_category[word2vec_prediction_str] \n",
    "    \n",
    "    # use bigrams (for cases of negation like \"not good\") and trigrams (for cases with numbers like \"bought 3 pairs\") \n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "    \n",
    "    # fit vectorizer to the product review titles and messages \n",
    "    vectorizer.fit(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "    \n",
    "    # result_matrix contains each document's TF_IDF scores \n",
    "    resulting_matrix = vectorizer.transform(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "        \n",
    "    product_id = product_reviews_by_category[word2vec_prediction_str][\"product_id\"].tolist() \n",
    "        \n",
    "    resulting_matrix = pd.DataFrame(resulting_matrix.toarray(), index=product_id, columns=vectorizer.get_feature_names_out()) \n",
    "    \n",
    "    # determine product in category that's most similar to user input \n",
    "    user_input_TF_IDF_vector = vectorizer.transform([user_input]) \n",
    "    # similarity of user input word vector and each of the rows' word vectors \n",
    "    similarity = cosine_similarity(user_input_TF_IDF_vector, resulting_matrix) \n",
    "    greatest_similarity_indices = np.argsort(similarity[0][::-1]) \n",
    "    greatest_similarity_product_ids = resulting_matrix.index[greatest_similarity_indices] \n",
    "    greatest_similarity_product_ids_list = greatest_similarity_product_ids.unique().tolist() \n",
    "    \n",
    "    # rows with that product id \n",
    "    products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[0]] \n",
    "    \n",
    "    clear_output(wait=True) \n",
    "    \n",
    "    print(\"\\nHow about this product?\") \n",
    "    print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "    print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "    print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "    more_detail_user_input = input(\"\\nDo you want more detail about this product? (Y/N)\") \n",
    "    \n",
    "    more_detail_user_input = more_detail_user_input.upper().strip() \n",
    "    \n",
    "    more_recommendations = \"N\" \n",
    "    more_detail = \"\" \n",
    "    moree = False \n",
    "    user_input_product_cat = \"\" \n",
    "    user_input = \"\" \n",
    "    \n",
    "    if more_detail_user_input == \"Y\": \n",
    "        print(\"\\nOk. Here is more detail about the product.\") \n",
    "        print(\"Total Orders: \", len(products_df)) \n",
    "        print(\"Product Weight (g): \", products_df[\"product_weight_g\"].iloc[0]) \n",
    "        print(\"Product Length (cm): \", products_df[\"product_length_cm\"].iloc[0]) \n",
    "        print(\"Product Height (cm): \", products_df[\"product_height_cm\"].iloc[0]) \n",
    "        print(\"Product Width (cm): \", products_df[\"product_width_cm\"].iloc[0]) \n",
    "        \n",
    "        good = input(\"\\nIs this a good recommendation? (Y/N)\") \n",
    "        good = good.upper().strip() \n",
    "    \n",
    "        if good == \"Y\": \n",
    "            another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "            another = another.upper().strip() \n",
    "            \n",
    "            if another == \"Y\": \n",
    "                token_vectors = []; \n",
    "            else: \n",
    "                print(\"\\nHave a great day! :)\") \n",
    "                break \n",
    "        \n",
    "        else: \n",
    "            print(\"\\nWe're sorry.\") \n",
    "            token_vectors = []; \n",
    "    \n",
    "    else: \n",
    "        more_recommendations = input(\"\\nWould you like more similar product recommendations? (Y/N)\") \n",
    "        more_recommendations = more_recommendations.upper().strip() \n",
    "    \n",
    "    if more_recommendations == \"Y\": \n",
    "        print(\"\\nOk. Here are some more product recommendations.\") \n",
    "        if (len(greatest_similarity_product_ids_list) == 3) | (len(greatest_similarity_product_ids_list) > 3): \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "        \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[2]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "            good = input(\"\\nWere any of these recommendations helpful? (Y/N)\") \n",
    "            good = good.upper().strip() \n",
    "    \n",
    "            if good == \"Y\": \n",
    "                another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "                another = another.upper().strip() \n",
    "                \n",
    "                if another == \"Y\": \n",
    "                    token_vectors = []; \n",
    "                else: \n",
    "                    print(\"\\nHave a great day! :)\") \n",
    "                    break \n",
    "            \n",
    "            else: \n",
    "                token_vectors = []; \n",
    "                print(\"\\nWe're sorry.\") \n",
    "    \n",
    "        elif len(greatest_similarity_product_ids_list) == 2: \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "        \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "            good = input(\"\\nWere any of these recommendations helpful? (Y/N)\") \n",
    "            good = good.upper().strip() \n",
    "    \n",
    "            if good == \"Y\": \n",
    "                another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "                another = another.upper().strip() \n",
    "                \n",
    "                if another == \"Y\": \n",
    "                    token_vectors = []; \n",
    "                else: \n",
    "                    print(\"\\nHave a great day! :)\") \n",
    "                    break \n",
    "            \n",
    "            else: \n",
    "                token_vectors = []; \n",
    "                print(\"\\nWe're sorry.\") \n",
    "    \n",
    "        else: \n",
    "            moree = True \n",
    "            \n",
    "            more_detail = input(\"\\nThere are no more similar products. What category is your product in? Enter number.\") \n",
    "    \n",
    "            # a dictionary with a number associated with each product category \n",
    "            product_categories_dict = {} \n",
    "        \n",
    "            # array with unique product categories \n",
    "            product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "        \n",
    "            for i in range(len(product_categories)): \n",
    "                product_categories_dict[i+1] = product_categories[i] \n",
    "        \n",
    "            # ask user for product category \n",
    "            print(\"\\nWhich category is the product in? Enter in number.\") \n",
    "            for keys, values in product_categories_dict.items(): \n",
    "                print(f\"{keys}: {values}\") \n",
    "            \n",
    "            user_input_2 = input(\"\") \n",
    "            \n",
    "            user_input_2 = int(user_input_2.strip()) \n",
    "            \n",
    "            user_input_product_cat = product_categories_dict.get(user_input_2) \n",
    "\n",
    "    else: \n",
    "        if (more_detail_user_input != \"Y\") & (another != \"Y\"): \n",
    "            print(\"\\nHave a great day! :)\") \n",
    "            break \n",
    "    \n",
    "    if moree == True: \n",
    "        user_product_category = df[df[\"product_cat_name_translated\"] == user_input_product_cat] \n",
    "        ranked_products = user_product_category.sort_values(by=\"review_score\", ascending=False) \n",
    "        \n",
    "        print(\"\\nHere are the three highest ranked products in that category.\") \n",
    "        print(ranked_products.head(3)[\"product_id\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58087f4-0812-4718-960f-0a0c20c58431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
