{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548d641b-ba6c-4ea7-87fd-1ec0d42817d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "face3bf3-51b5-4b89-85c4-048101db5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "!pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f9a565-f6a5-4ac8-866e-809ca820b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.0\n",
      "Uninstalling numpy-1.26.0:\n",
      "  Successfully uninstalled numpy-1.26.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.0\n",
      "  Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (53 kB)\n",
      "Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tableone 0.9.1 requires openpyxl>=3.1.2, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy --yes \n",
    "!pip install numpy==1.26.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab76ba79-4a1c-4dbc-bef8-f0d73062ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d31d1d1-12b4-4b8a-9047-8ba5f46ec83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/jocelyn/Desktop/DXC-4 Technology /AI-Enhanced-Customer-Interaction-Assistant/data/Final_db.csv\" \n",
    "df = pd.read_csv(filename, header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d22ab8a-4ac4-4dd7-bd31-980d484d9236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "2  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "3  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "4  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "1    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "2    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "3    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
      "4    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "2          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "3          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "4          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "\n",
      "  order_estimated_delivery_date                         review_id  \\\n",
      "0           2017-10-18 00:00:00  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "1           2017-10-18 00:00:00  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "2           2017-10-18 00:00:00  a54f0611adc9ed256b57ede6b6eb5114   \n",
      "3           2018-08-13 00:00:00  8d5266042046a06655c8db133d120ba5   \n",
      "4           2018-09-04 00:00:00  e73b67b67587f7644d5bd1a52deb1b01   \n",
      "\n",
      "   review_score  ... product_height_cm product_width_cm  \\\n",
      "0           4.0  ...               8.0             13.0   \n",
      "1           4.0  ...               8.0             13.0   \n",
      "2           4.0  ...               8.0             13.0   \n",
      "3           4.0  ...              13.0             19.0   \n",
      "4           5.0  ...              19.0             21.0   \n",
      "\n",
      "                 customer_unique_id customer_zip_code_prefix  customer_city  \\\n",
      "0  7c396fd4830fd04220f754e42b4e5bff                     3149      sao paulo   \n",
      "1  7c396fd4830fd04220f754e42b4e5bff                     3149      sao paulo   \n",
      "2  7c396fd4830fd04220f754e42b4e5bff                     3149      sao paulo   \n",
      "3  af07308b275d755c9edb36a90c618231                    47813      barreiras   \n",
      "4  3a653a41f6f9fc3d2a113cf8398680e8                    75265     vianopolis   \n",
      "\n",
      "  customer_state  seller_zip_code_prefix     seller_city  seller_state  \\\n",
      "0             SP                  9350.0            maua            SP   \n",
      "1             SP                  9350.0            maua            SP   \n",
      "2             SP                  9350.0            maua            SP   \n",
      "3             BA                 31570.0  belo horizonte            SP   \n",
      "4             GO                 14840.0         guariba            SP   \n",
      "\n",
      "  product_cat_name_translated  \n",
      "0                  housewares  \n",
      "1                  housewares  \n",
      "2                  housewares  \n",
      "3                   perfumery  \n",
      "4                        auto  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
      "       'order_approved_at', 'order_delivered_carrier_date',\n",
      "       'order_delivered_customer_date', 'order_estimated_delivery_date',\n",
      "       'review_id', 'review_score', 'review_comment_title',\n",
      "       'review_comment_message', 'review_creation_date',\n",
      "       'review_answer_timestamp', 'payment_sequential', 'payment_type',\n",
      "       'payment_installments', 'payment_value', 'order_item_id', 'product_id',\n",
      "       'seller_id', 'shipping_limit_date', 'price', 'freight_value',\n",
      "       'product_category_name', 'product_name_lenght',\n",
      "       'product_description_lenght', 'product_photos_qty', 'product_weight_g',\n",
      "       'product_length_cm', 'product_height_cm', 'product_width_cm',\n",
      "       'customer_unique_id', 'customer_zip_code_prefix', 'customer_city',\n",
      "       'customer_state', 'seller_zip_code_prefix', 'seller_city',\n",
      "       'seller_state', 'product_cat_name_translated'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.head()) \n",
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9320b65c-b64d-4fb7-b0db-a826669831a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id\n",
      "aca2eb7d00ea1a7b8ebd4e68314663af    536\n",
      "99a4788cb24856965c36a24e339b6058    528\n",
      "422879e10f46682990de24d770e7f83d    508\n",
      "389d119b48cf3043d311335e499d9c6b    406\n",
      "368c6c730842d78016ad823897a372db    398\n",
      "                                   ... \n",
      "ef34878717e7759a53c99550100ea1ec      1\n",
      "6965419e0d5116b685c3f825e4752231      1\n",
      "a2d0ef58f86a42fa9d456709cb00c0b2      1\n",
      "4e1d8ab59a756d83db0a0902c1342e11      1\n",
      "006619bbed68b000c8ba3f8725d5409e      1\n",
      "Name: count, Length: 32951, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check to see if there are products with multiple orders \n",
    "product_id_value_counts = df[\"product_id\"].value_counts() \n",
    "print(product_id_value_counts) \n",
    "\n",
    "# store the products with multiple orders in products_multiple_orders \n",
    "products_multiple_orders = product_id_value_counts[product_id_value_counts > 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae07ca3-8e33-48f9-b4d0-e2fbe6d61e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              product_id  times_purchased\n",
      "0       87285b34884572647811a353c7ac498a              6.0\n",
      "1       87285b34884572647811a353c7ac498a              6.0\n",
      "2       87285b34884572647811a353c7ac498a              6.0\n",
      "3       595fac2a385ac33a80bd5114aec74eb8            106.0\n",
      "4       aa4383b373c6aca5d8797843e5594415              3.0\n",
      "...                                  ...              ...\n",
      "119138  f1d4ce8c6dd66c47bbaa8c6781c2a923             19.0\n",
      "119139  b80910977a37536adeddd63663f916ad              3.0\n",
      "119140  d1c427060a0f73f6b889a5c7c61f2ac4            357.0\n",
      "119141  d1c427060a0f73f6b889a5c7c61f2ac4            357.0\n",
      "119142  006619bbed68b000c8ba3f8725d5409e              1.0\n",
      "\n",
      "[119143 rows x 2 columns]\n",
      "                                order_id                       customer_id  \\\n",
      "54      25f4376934e13d3508486352e11a5db0  12fd2740039676063a874b9567dfa651   \n",
      "238     6d7de866a140b19d09e825b2a4e944c7  9e5ce657315b2bdb94033a494041ac25   \n",
      "239     6d7de866a140b19d09e825b2a4e944c7  9e5ce657315b2bdb94033a494041ac25   \n",
      "267     a0d5b8474423ddf55228373b81a46272  3f7d26944f7f68bd2ac23b5e8b500ab0   \n",
      "769     f29d0fd6d4e6d5ce550e0b2f9335116c  55216cd56c9eaadec16f03d5aaf11d86   \n",
      "...                                  ...                               ...   \n",
      "116825  1f52d261d5a103a2a2375c21c99cd08d  6ec06eba01982607b43609eae1f3798b   \n",
      "116843  9d01fa0e65583ec53f3864ee0e73d015  91d8e6ba148d6e55b4bb98a7af766101   \n",
      "117630  15847be2cbb3423e9344e53b040ef2a6  38658a45235ad07f51a84607654e53f1   \n",
      "118048  ac88d96f79bb0884df747b9c38fe48f7  ced8f3419d9a7d7fec840b843b36d6c2   \n",
      "118278  b811c8ca07716586e80c0bc4f2a6e39f  a7dd8bd4bdbdc55196a8ee7fd336dde7   \n",
      "\n",
      "       order_status order_purchase_timestamp    order_approved_at  \\\n",
      "54        delivered      2018-05-17 16:59:11  2018-05-18 01:17:39   \n",
      "238       delivered      2018-04-16 21:07:16  2018-04-16 22:10:15   \n",
      "239       delivered      2018-04-16 21:07:16  2018-04-16 22:10:15   \n",
      "267       delivered      2018-01-11 16:51:17  2018-01-12 02:38:34   \n",
      "769       delivered      2018-05-17 16:34:49  2018-05-19 02:59:02   \n",
      "...             ...                      ...                  ...   \n",
      "116825    delivered      2018-05-09 12:27:01  2018-05-09 12:55:48   \n",
      "116843    delivered      2018-02-13 21:54:39  2018-02-14 21:50:28   \n",
      "117630    delivered      2018-01-13 00:21:59  2018-01-13 00:58:27   \n",
      "118048    delivered      2018-03-11 18:14:17  2018-03-11 18:28:00   \n",
      "118278    delivered      2018-04-20 18:29:15  2018-04-24 18:49:01   \n",
      "\n",
      "       order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "54              2018-05-18 13:02:00           2018-05-21 15:22:11   \n",
      "238             2018-04-17 20:54:27           2018-04-24 20:38:55   \n",
      "239             2018-04-17 20:54:27           2018-04-24 20:38:55   \n",
      "267             2018-01-15 17:24:13           2018-01-22 21:18:33   \n",
      "769             2018-05-21 13:45:00           2018-06-09 00:14:23   \n",
      "...                             ...                           ...   \n",
      "116825          2018-05-10 12:07:00           2018-05-11 20:57:36   \n",
      "116843          2018-02-16 00:09:36           2018-03-17 14:36:27   \n",
      "117630          2018-01-15 23:51:49           2018-02-01 01:53:10   \n",
      "118048          2018-03-12 23:18:58           2018-04-15 15:28:40   \n",
      "118278          2018-04-23 18:28:42           2018-05-01 00:32:42   \n",
      "\n",
      "       order_estimated_delivery_date                         review_id  \\\n",
      "54               2018-05-25 00:00:00  ff130b68d99d6cedd7329b13ffbe2f03   \n",
      "238              2018-05-15 00:00:00  efe78d9472d99a721249768f9cde52a8   \n",
      "239              2018-05-15 00:00:00  efe78d9472d99a721249768f9cde52a8   \n",
      "267              2018-02-07 00:00:00  8fff1cbcebc74fe97c4cb9320a46d2f0   \n",
      "769              2018-06-13 00:00:00  a5c5076bbb5504f3c40c9ab7587f9851   \n",
      "...                              ...                               ...   \n",
      "116825           2018-05-17 00:00:00  d474530e097b04caed32632bf3aaa186   \n",
      "116843           2018-03-05 00:00:00  a0b7b8341d904f0ce5a3c432e0ca3747   \n",
      "117630           2018-02-09 00:00:00  4e1f6d6be3ffe82538bce490e6ffeb63   \n",
      "118048           2018-04-05 00:00:00  29ffb6f92601615e450be1a608cf5d2a   \n",
      "118278           2018-05-21 00:00:00  f1aefb9b3293cdea695d8dcb63c2f842   \n",
      "\n",
      "        review_score  ... product_width_cm                customer_unique_id  \\\n",
      "54               5.0  ...             30.0  372e0fc66eacb8698e4f9997d366d961   \n",
      "238              2.0  ...             30.0  51cbfa44126505de7a55fb99ba49648b   \n",
      "239              2.0  ...             30.0  51cbfa44126505de7a55fb99ba49648b   \n",
      "267              5.0  ...             30.0  c8d183727fc9b4dcac256fbe246d6270   \n",
      "769              5.0  ...             30.0  c1dc1162de49817a25314db3030276f5   \n",
      "...              ...  ...              ...                               ...   \n",
      "116825           5.0  ...             30.0  b760002a61b395c5b9ef77e7a424c037   \n",
      "116843           2.0  ...             30.0  146057bc81d21cc0aa170797de177ed8   \n",
      "117630           2.0  ...             30.0  0950a89e2269d0042c403550ac89a787   \n",
      "118048           1.0  ...             30.0  61f37e13b99dae825118a5003486b934   \n",
      "118278           5.0  ...             30.0  a9747b164275fabdd901a9fc169c5251   \n",
      "\n",
      "       customer_zip_code_prefix        customer_city  customer_state  \\\n",
      "54                        12230  sao jose dos campos              SP   \n",
      "238                       88132              palhoca              SC   \n",
      "239                       88132              palhoca              SC   \n",
      "267                       79112         campo grande              MS   \n",
      "769                       99435        campos borges              RS   \n",
      "...                         ...                  ...             ...   \n",
      "116825                     4816            sao paulo              SP   \n",
      "116843                    24744          sao goncalo              RJ   \n",
      "117630                    57083               maceio              AL   \n",
      "118048                    24935               marica              RJ   \n",
      "118278                    26173         belford roxo              RJ   \n",
      "\n",
      "       seller_zip_code_prefix  seller_city  seller_state  \\\n",
      "54                     4782.0    sao paulo            SP   \n",
      "238                    4782.0    sao paulo            SP   \n",
      "239                    4782.0    sao paulo            SP   \n",
      "267                    4782.0    sao paulo            SP   \n",
      "769                    4782.0    sao paulo            SP   \n",
      "...                       ...          ...           ...   \n",
      "116825                 4782.0    sao paulo            SP   \n",
      "116843                 4782.0    sao paulo            SP   \n",
      "117630                 4782.0    sao paulo            SP   \n",
      "118048                 4782.0    sao paulo            SP   \n",
      "118278                 4782.0    sao paulo            SP   \n",
      "\n",
      "        product_cat_name_translated times_purchased  \n",
      "54                  furniture_decor           536.0  \n",
      "238                 furniture_decor           536.0  \n",
      "239                 furniture_decor           536.0  \n",
      "267                 furniture_decor           536.0  \n",
      "769                 furniture_decor           536.0  \n",
      "...                             ...             ...  \n",
      "116825              furniture_decor           536.0  \n",
      "116843              furniture_decor           536.0  \n",
      "117630              furniture_decor           536.0  \n",
      "118048              furniture_decor           536.0  \n",
      "118278              furniture_decor           536.0  \n",
      "\n",
      "[536 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a new column in df that stores the number of times each item was purchased \n",
    "df[\"times_purchased\"] = df[\"product_id\"].map(product_id_value_counts) \n",
    "\n",
    "# check to see if the column is correctly added in \n",
    "print(df[[\"product_id\", \"times_purchased\"]]) \n",
    "print(df[df[\"product_id\"] == \"aca2eb7d00ea1a7b8ebd4e68314663af\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c5b85c7-170f-4772-8a1a-f91f0f476334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# items purchased multiple times \n",
    "# average rating \n",
    "\n",
    "# summary of all reviews for that product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770ad5fe-4b1e-4a95-9429-e7cc6c87244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d189804d-26ac-476a-9f47-cd68440e8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores all of the unique product categories into the array \"product_categories\" \n",
    "product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "\n",
    "\"\"\" \n",
    "# output product_categories \n",
    "print(product_categories) \n",
    "\"\"\" \n",
    "\n",
    "\"\"\" \n",
    "# check if there are any rows where the product review titles are filled out, and the product review messages aren't \n",
    "# result --> there are \n",
    "review_titles_with_no_reviews = df[df[\"review_comment_title\"].notna() & df[\"review_comment_message\"].isna()] \n",
    "print(\"________________\") \n",
    "print(review_titles_with_no_reviews[\"review_comment_message\"]) \n",
    "\"\"\" \n",
    "\n",
    "# fill in rows in df[\"review_comment_title\"] column that have na values with \"\" \n",
    "df[\"review_comment_title\"] = df[\"review_comment_title\"].fillna(\"\") \n",
    "\n",
    "# fill in rows in df[\"review_comment_message\"] column that have na values with \"\" \n",
    "df[\"review_comment_message\"] = df[\"review_comment_message\"].fillna(\"\") \n",
    "\n",
    "# merge the product reviews and product review titles with a space in between both \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"review_comment_message\"] + \" \" + df[\"review_comment_title\"] \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"merged_review_messages_and_titles\"].str.strip() \n",
    "\n",
    "# dictionary to store dataframes of the product reviews for all products in each category \n",
    "# products are separated by category \n",
    "product_reviews_by_category = {}; \n",
    "\n",
    "# fill in dictionary with keys (df category) and values (product_id and product reviews for all products in that category) \n",
    "for category in product_categories: \n",
    "    product_reviews_by_category[\"df_\" + str(category)] = df[df[\"product_cat_name_translated\"] == category][[\"product_id\", \"merged_review_messages_and_titles\"]] \n",
    "\n",
    "# output product_reviews_by_category \n",
    "#for key, value in product_reviews_by_category.items(): \n",
    "#    print(\"\\n\") \n",
    "    # product category \n",
    "#    print(key + \"\\n\") \n",
    "    # product reviews \n",
    "#    print(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a2dedb-4c92-4773-a4ad-c6fe64f0b5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer for df_housewares\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_perfumery\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_auto\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_pet_shop\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_stationery\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_miscellaneous\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_furniture_decor\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_office_furniture\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_garden_tools\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_computers_accessories\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_bed_bath_table\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_toys\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_construction_tools_construction\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_telephony\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_health_beauty\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_electronics\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_baby\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_cool_stuff\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_watches_gifts\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_air_conditioning\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_sports_leisure\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_books_general_interest\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_small_appliances\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_food\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_luggage_accessories\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fashion_underwear_beach\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_christmas_supplies\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fashion_bags_accessories\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_musical_instruments\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_construction_tools_lights\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_books_technical\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_costruction_tools_garden\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_home_appliances\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_market_place\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_agro_industry_and_commerce\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_party_supplies\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_home_confort\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_cds_dvds_musicals\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_industry_commerce_and_business\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_consoles_games\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_furniture_bedroom\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_construction_tools_safety\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fixed_telephony\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_drinks\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_kitchen_dining_laundry_garden_furniture\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fashion_shoes\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_home_construction\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_audio\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_home_appliances_2\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fashion_male_clothing\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_cine_photo\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_furniture_living_room\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_art\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_food_drink\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_tablets_printing_image\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fashion_sport\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_la_cuisine\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_flowers\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_computers\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_home_comfort_2\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_small_appliances_home_oven_and_coffee\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_dvds_blu_ray\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_costruction_tools_tools\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fashio_female_clothing\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_furniture_mattress_and_upholstery\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_signaling_and_security\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_diapers_and_hygiene\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_books_imported\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_fashion_childrens_clothes\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_music\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_arts_and_craftmanship\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n",
      "TfidfVectorizer for df_security_and_services\n",
      "--------------------------------------------------------------------------------------\n",
      "**************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "TF-IDF to distinguish between different products in same category \n",
    "\"\"\" \n",
    "\n",
    "# dictionary that contains the produced matrix for all product categories \n",
    "resulting_matrices = {} \n",
    "\n",
    "# every row (product review) in the df is treated as a document \n",
    "for keys, values in product_reviews_by_category.items(): \n",
    "    print(f\"TfidfVectorizer for {keys}\") \n",
    "    print(\"--------------------------------------------------------------------------------------\") \n",
    "\n",
    "    # use bigrams (for cases of negation like \"not good\") and trigrams (for cases with numbers like \"bought 3 pairs\") \n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "\n",
    "    # fit vectorizer to the product review titles and messages \n",
    "    vectorizer.fit(values[\"merged_review_messages_and_titles\"]) \n",
    "\n",
    "#    print(\"Vocabulary size {0}: {1}\\n\".format(len(vectorizer.vocabulary_), vectorizer.vocabulary_.items())) \n",
    "\n",
    "#    print(\"Matrix:\\n\") \n",
    "    # result_matrix contains each document's TF_IDF scores \n",
    "    resulting_matrix = vectorizer.transform(values[\"merged_review_messages_and_titles\"]) \n",
    "\n",
    "    print(\"**************************************************************************************\") \n",
    "#    print(vectorizer.get_feature_names_out()) \n",
    "    \n",
    "    product_id = values[\"product_id\"].tolist() \n",
    "    \n",
    "    resulting_matrix = pd.DataFrame(resulting_matrix.toarray(), index=product_id, columns=vectorizer.get_feature_names_out()) \n",
    "    \n",
    "    # resulting_matrices is a dictionary containing the resulting_matrix for all product categories \n",
    "    key_name = f\"resulting_matrix_{keys}\" \n",
    "    resulting_matrices[key_name] = resulting_matrix \n",
    "    \n",
    "#    print(resulting_matrix.todense()) \n",
    "\n",
    "#    print(\"\\nHeatmap of Matrix:\\n\") \n",
    "#    df_print = pd.DataFrame(resulting_matrix.toarray(), columns=vectorizer.get_feature_names_out()) \n",
    "#   plt.rcParams['figure.figsize'] = [11, 11] \n",
    "#    ax = sns.heatmap(df_print, annot=True, cmap='coolwarm', cbar=False, \n",
    "#                     yticklabels=[f\"Document {i+1}:\" for i in range(len(values))]) \n",
    "#    _ =ax.set_title(f'TF-IDF Matrix {keys}');\n",
    "#    _ =ax.set_yticklabels(ax.get_yticklabels(), rotation = 0, fontsize = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0acddaf-7eb9-4c81-a505-fccc272e948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if resulting_matrices contains the various matrices with product_id as index and individual columns for each n-gram \n",
    "#for key, values in resulting_matrices.items(): \n",
    "#    print(key) \n",
    "#    print(values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35c061e7-e194-4b92-a9a5-a55d451975e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace document number with product_id, and replace term index with the actual term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c9f3a30-70d6-4e84-ae14-0229de0e2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze inputted user response and determine which product best matches it \n",
    "# look at distinguishing features across categories \n",
    "# ask user \"is this good?\" \n",
    "# if yes, then also output other related recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fddd83e-b33e-40ca-b879-bf38382eb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "357e1ad0-c231-4e39-95b5-2fedd85b593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80bce9f6-a90c-4f5e-8f88-5f6373f11a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a244f929-5a25-4850-992d-4f0f43c8c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recommend', 'me', 'sturdy', 'chair']\n"
     ]
    }
   ],
   "source": [
    "# sample_user_input \n",
    "sample_user_input = \"Recommend me a sturdy chair\" \n",
    "\n",
    "# preprocess user input ~ \"this lowercases [and] tokenizes\"; stop words get removed \n",
    "sample_user_input = list(gensim.utils.simple_preprocess(sample_user_input)) \n",
    "print(sample_user_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da26ce52-38d8-4fbf-be0a-9e9c94c648f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ~ product title and review \n",
    "X = df[\"merged_review_messages_and_titles\"] \n",
    "\n",
    "# label ~ product category \n",
    "y = df[\"product_cat_name_translated\"] \n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# vectorizer = CountVectorizer(ngram_range=(2, 3)) \n",
    "# X_n = vectorizer.fit_transform(df[\"merged_review_messages_and_titles\"]) \n",
    "# product_id = df[\"product_id\"].tolist() \n",
    "    \n",
    "# resulting_matrix = pd.DataFrame(X_n.toarray(), index=product_id, columns=vectorizer.get_feature_names_out())     \n",
    "# print(resulting_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa4851e3-6cca-48c6-86a2-d6ed4d9aa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess each (each row) product title and review \n",
    "X = X.apply(lambda row: gensim.utils.simple_preprocess(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3181b36c-2713-4923-bdef-a40ba6579ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [não, testei, produto, ainda, mas, ele, veio, ...\n",
      "1         [não, testei, produto, ainda, mas, ele, veio, ...\n",
      "2         [não, testei, produto, ainda, mas, ele, veio, ...\n",
      "3                   [muito, bom, produto, muito, boa, loja]\n",
      "4                                                        []\n",
      "                                ...                        \n",
      "119138    [so, uma, peça, que, veio, rachado, mas, tudo,...\n",
      "119139                    [foi, entregue, antes, do, prazo]\n",
      "119140    [foi, entregue, somente, quero, saber, do, out...\n",
      "119141    [foi, entregue, somente, quero, saber, do, out...\n",
      "119142                                                   []\n",
      "Name: merged_review_messages_and_titles, Length: 119143, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# each row in X is now tokenized \n",
    "print(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0376667a-d425-40ba-9058-96560e81d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into a training set and a test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=1111) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21f6d8b0-d97a-421d-b803-a3876c193f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "End\n",
      "14005\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin\") \n",
    "word2vec_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=1) \n",
    "print(\"End\") \n",
    "print(len(word2vec_model.wv.key_to_index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78028926-e5df-476d-a502-08a0b4a1766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression to determine which category the user input product likely belongs to \n",
    "# look in the category and use word vectors to determine which product is most similar to \n",
    "# the one that the user is looking for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0791ba30-1723-4db8-af11-285e7addd7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14005\n"
     ]
    }
   ],
   "source": [
    "# size of word2vec_model \n",
    "print(len(word2vec_model.wv.key_to_index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8db70082-91d0-4002-8dc5-d0f567444542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gostaria', 0.9232568740844727), ('receber', 0.8663808107376099), ('vão', 0.8646805286407471), ('vai', 0.8601102828979492), ('devolver', 0.8566531538963318), ('verificar', 0.8530604839324951), ('responder', 0.8529185652732849), ('querer', 0.8502118587493896), ('mandar', 0.8437370657920837), ('preciso', 0.8415015935897827)]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model.wv.most_similar(\"saber\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "052291d5-165b-4413-896a-be9c2c99a57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Transforming X_train\n",
      "Finish Transforming X_train\n",
      "Begin Transforming X_test\n",
      "Finish Transforming X_test\n"
     ]
    }
   ],
   "source": [
    "# replace every word in the dataset that's also found in word2vec_model with their word embedding \n",
    "# a set with all of the unique words in the word2vex_model \n",
    "words = set(word2vec_model.wv.index_to_key) \n",
    "\n",
    "# X_train word embeddings \n",
    "print(\"Begin Transforming X_train\") \n",
    "# array for all of the word embeddings for X_train \n",
    "X_train_word_embeddings = []; \n",
    "for row in X_train: \n",
    "    row_embedding = [] \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_train_word_embeddings.append(np.array(row_embedding)) \n",
    "print(\"Finish Transforming X_train\") \n",
    "\n",
    "# X_test word embeddings \n",
    "print(\"Begin Transforming X_test\") \n",
    "# array for all of the word embeddings for X_test \n",
    "X_test_word_embeddings = []; \n",
    "for row in X_test: \n",
    "    row_embedding = []; \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_test_word_embeddings.append(np.array(row_embedding)) \n",
    "print(\"Finish Transforming X_test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6829743c-1c99-4404-8d3e-13ed39446f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.14534935,  0.27452433, -0.2145524 , -0.02878416, -0.10788985,\n",
      "       -0.6340307 ,  0.10151728,  1.011183  , -0.8562664 , -0.88614243,\n",
      "       -0.11211656, -0.24360485,  0.21715567,  0.00991838,  0.06129951,\n",
      "       -0.20033026,  0.46333212, -0.30022234, -0.33242127, -0.80321395,\n",
      "        0.2852601 , -0.41565737,  0.6484374 , -0.04431574, -0.23141341,\n",
      "        0.39273864, -0.53634727, -0.3802703 , -0.32483652,  0.22657308,\n",
      "        0.2649581 ,  0.09945676, -0.03661419, -0.48914558, -0.1765134 ,\n",
      "        0.28487983, -0.2973519 , -0.19904219, -0.05482539, -1.0271875 ,\n",
      "       -0.1263994 , -0.10191493,  0.5928837 , -0.09143305,  0.36543384,\n",
      "       -0.17244683,  0.2323604 , -0.07332067,  0.68673503,  0.3599605 ,\n",
      "       -0.13491507,  0.39980087, -0.53309757, -0.34677768, -0.22100243,\n",
      "        0.14588962,  0.14750572, -0.00938067, -0.6291674 , -0.00225136,\n",
      "        0.15668334,  0.33433694,  0.12998112,  0.7241155 , -0.05167149,\n",
      "        0.65649873,  0.27733213,  0.6207763 , -0.70339966,  0.1617473 ,\n",
      "        0.1310721 ,  0.58871716,  0.5330141 ,  0.09330387,  0.8113125 ,\n",
      "       -0.27152634, -0.03754939,  0.34408653,  0.10380773, -0.03772324,\n",
      "       -0.14532411, -0.17043951, -0.4950735 ,  0.46031874, -0.3367985 ,\n",
      "       -0.6021638 ,  0.40666014,  1.0208235 ,  0.58984363, -0.01143769,\n",
      "        0.29985934,  0.57657814,  0.046714  , -0.22672077,  0.36888036,\n",
      "       -0.1793309 , -0.06060745, -0.45095253,  0.13548437, -0.1716906 ],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.35790393,  0.14634226, -0.27675295, -0.34350097,  0.17617822,\n",
      "       -0.40497255, -0.15323563,  0.47416234, -0.32004678,  0.5256529 ,\n",
      "       -0.13350186, -0.67298263,  0.3047188 ,  0.3904762 ,  0.38197225,\n",
      "       -0.7338532 , -0.01137508, -0.2798187 ,  0.45917067, -0.71602094,\n",
      "       -0.18334268,  0.0029088 , -0.05534816, -0.31734842, -0.41262665,\n",
      "        0.9716377 , -0.11730494, -0.73060244, -0.3852395 , -0.00457632,\n",
      "        0.51346767,  0.03789617,  0.6720263 , -0.04388047, -0.24911949,\n",
      "        0.26426977,  0.2740477 , -0.389327  , -0.23479801, -0.9329907 ,\n",
      "       -0.02347278, -0.80884653, -0.36174226,  0.33312434, -0.19137202,\n",
      "       -0.45688432, -0.32117015, -0.14271392,  0.01948327, -0.30415648,\n",
      "        0.26202318, -0.25881577,  0.3716097 ,  0.1718142 ,  0.03807025,\n",
      "        0.1754501 , -0.32612833, -0.12362574, -0.7167394 ,  0.35594827,\n",
      "        0.48649132, -0.3869502 ,  0.06207169,  0.581697  , -0.69801414,\n",
      "        0.44501418, -0.26741913, -0.19409186, -0.8327675 ,  0.69975543,\n",
      "       -0.9049392 ,  0.32131666,  0.6809758 , -0.6832297 , -0.06237596,\n",
      "        0.48583782, -0.433059  ,  0.2806788 , -0.6782833 , -0.1131409 ,\n",
      "        0.00254193,  0.29468268, -1.0560081 ,  0.44439328, -0.40546453,\n",
      "        0.07231092,  0.15395546,  1.1075418 ,  0.13433501, -0.18145485,\n",
      "        1.0153768 ,  0.10989214,  0.40894985,  0.47413936,  0.91359144,\n",
      "        0.12814626, -0.1252679 , -0.00313392,  0.39924452, -0.08986139],\n",
      "      dtype=float32), array([-0.48742843,  0.36832058,  0.04216556, -0.04440899,  0.24876213,\n",
      "       -0.6951174 ,  0.29721686,  0.2928224 , -0.43417624,  0.04381181,\n",
      "        0.17435853,  0.2828025 ,  0.5134336 ,  0.00856477,  0.49325565,\n",
      "       -0.24907322,  0.69899696, -0.14875035, -0.30701843, -1.4700732 ,\n",
      "        0.555445  , -0.09033421,  0.8734341 ,  0.08403365, -0.55257595,\n",
      "        0.49413705, -0.20057873, -0.30493626, -0.26986647,  0.4401592 ,\n",
      "        0.961874  ,  0.5381045 ,  0.21935336, -0.3862821 , -0.27465537,\n",
      "        0.71335477, -0.16022909, -0.54911005, -0.7373035 , -0.8671236 ,\n",
      "        0.5468691 , -0.60140365,  0.9199195 ,  0.25632837,  0.5810377 ,\n",
      "        0.09702794, -0.15568383, -0.37723538,  0.59333986, -0.18065377,\n",
      "        0.9368312 , -0.67324495, -0.37315056, -0.12336906, -0.89895815,\n",
      "       -0.27321038, -0.3483572 ,  0.28151816, -0.647388  ,  0.20047061,\n",
      "        0.21404187,  0.14210935,  0.5337302 ,  0.15863441, -0.09398382,\n",
      "        0.44488254,  0.13817303,  0.8218673 , -0.9959333 ,  0.11609637,\n",
      "       -0.3548977 ,  0.5804147 , -0.01532341,  0.47241938,  1.0624093 ,\n",
      "        0.12693612,  0.09701268,  0.97390157, -0.3393407 ,  0.3351476 ,\n",
      "       -0.08499464,  0.33805367, -0.71840733,  0.49508795,  0.08181768,\n",
      "       -0.29149872,  0.44550797,  0.93813086,  0.2711438 , -0.26986927,\n",
      "        1.5218788 ,  0.39981684,  0.07614371,  0.21977514,  0.6737245 ,\n",
      "       -0.04878205,  0.74655795, -0.4745872 , -0.69327307,  0.2777793 ],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.55943537,  0.41209462, -0.04231982,  0.6877784 , -0.38148904,\n",
      "       -0.26258126, -0.30925587,  1.1990588 , -0.5497823 , -0.90029746,\n",
      "       -0.17813437, -0.70035094,  0.0696397 ,  0.42526284,  0.264171  ,\n",
      "       -0.37446257,  0.5820727 , -0.36008516,  0.40237954, -0.9821798 ,\n",
      "       -0.65259385, -0.12621404, -0.066949  ,  0.03202466, -0.5289795 ,\n",
      "       -0.9756859 , -0.9709418 , -0.25693896, -0.52506566,  0.3139769 ,\n",
      "        0.8505068 , -0.11032172, -0.7299183 , -0.2965283 , -0.42219296,\n",
      "        0.45682827, -0.03444266, -0.08335582,  0.2738016 , -0.57527333,\n",
      "        0.29501823, -0.06471977, -0.43261954, -0.3187664 ,  0.70847243,\n",
      "        0.19158494,  0.44793758,  0.15287279,  1.0308536 ,  0.37038407,\n",
      "        0.2660034 , -0.4685161 , -0.37620616,  0.45396197,  0.2796949 ,\n",
      "        0.991039  ,  0.68546724,  0.05433788, -0.46190378,  0.3616743 ,\n",
      "       -0.6423889 ,  0.9245629 , -0.5386769 , -0.3407496 ,  0.21457684,\n",
      "       -0.66359586, -0.04342065, -0.08103992, -1.0634588 , -0.02130125,\n",
      "        0.50343025,  0.6549634 ,  1.1341896 ,  0.34761873,  0.6687865 ,\n",
      "        0.0135538 , -0.18626732, -0.49184537, -0.61589354, -0.09686758,\n",
      "       -0.3208872 , -0.652543  , -0.00690774,  1.1194198 , -0.19234365,\n",
      "       -0.33959976, -0.35662928,  1.3443195 ,  1.1244549 ,  1.0834292 ,\n",
      "        0.7096296 ,  0.8562835 , -0.24892128,  0.9535826 ,  0.48290774,\n",
      "        0.86909485,  0.1681568 ,  0.13729247,  0.01734282, -0.25175348],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "X_train_feature_vector = []\n",
    "for w in X_train_word_embeddings:\n",
    "    if w.size:\n",
    "        X_train_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_train_feature_vector.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_feature_vector = []\n",
    "for w in X_test_word_embeddings:\n",
    "    if w.size:\n",
    "        X_test_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_test_feature_vector.append(np.zeros(100, dtype=float))\n",
    "\n",
    "print(X_train_feature_vector[1:11]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ea869dd-e50b-4fdf-88c4-1bfd49dd2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression \n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_feature_vector, y_train)\n",
    "\n",
    "probability_predictions = model.predict_proba(X_test_feature_vector) \n",
    "\n",
    "# predict most likely product category \n",
    "class_label_predictions = model.predict(X_test_feature_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf6e0b-2619-4283-bf1d-1afe507b1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_user_input_list = list(gensim.utils.simple_preprocess(sample_user_input)) \n",
    "#bigram_transformer = Phrases([sample_user_input_list]) \n",
    "#aa = list(bigram_transformer[sample_user_input_list]) \n",
    "#model = gensim.models.Word2Vec([aa], vector_size=200, window=5, min_count=1) \n",
    "#print(len(model.wv.key_to_index)) \n",
    "#print(model.wv.most_similar(\"me\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "acda2cdf-2f6e-4448-b64e-8255e85cca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi! What product are you looking for? jio\n",
      "We can't find a related product. Please input more detail. saber\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health_beauty']\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Hi! What product are you looking for?\") \n",
    "\n",
    "#user_input_word2vec_model = gensim.models.Word2Vec(user_input, vector_size=200, window=5, min_count=1) \n",
    "\n",
    "# preprocess user input ~ \"this lowercases [and] tokenizes\"; stop words get removed \n",
    "user_input_tokens = list(gensim.utils.simple_preprocess(user_input)) \n",
    "\n",
    "# create a list containing the vectors for the tokens/words found in the user input that are also found in the dataset of available products \n",
    "token_vectors = [] \n",
    "\n",
    "while len(token_vectors) == 0: \n",
    "    user_input_tokens = list(gensim.utils.simple_preprocess(user_input)) \n",
    "    token_vectors = [] \n",
    "    \n",
    "    # loop through all tokens from the tokenized version of the user input \n",
    "    for token in user_input_tokens: \n",
    "        # if the token is also found in the dataset \n",
    "        if token in word2vec_model.wv.key_to_index: \n",
    "            # add its word vector to the \"token_vectors\" list \n",
    "            token_vectors.append(word2vec_model.wv[token]) \n",
    "\n",
    "    # if there are vectors \n",
    "    if len(token_vectors) > 0: \n",
    "        # calculate the mean for each token_vector and combine into an array \n",
    "        overall_token_vector = np.mean(token_vectors, axis=0) \n",
    "        # reshape into a two dimensional array \n",
    "        overall_token_vector = token_vector.reshape(1, -1) \n",
    "        word2vec_prediction = model.predict(overall_token_vector) \n",
    "        print(word2vec_prediction) \n",
    "    \n",
    "    else: \n",
    "        user_input = input(\"We can't find a related product. Please input more detail.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5977adfa-2395-4801-b876-dbf580a99a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_prediction_str = \"df_\" + str(word2vec_prediction[0]) \n",
    "\n",
    "#vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "\n",
    "product_reviews_by_category[word2vec_prediction_str] \n",
    "\n",
    "# use bigrams (for cases of negation like \"not good\") and trigrams (for cases with numbers like \"bought 3 pairs\") \n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "\n",
    "# fit vectorizer to the product review titles and messages \n",
    "vectorizer.fit(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "\n",
    "# result_matrix contains each document's TF_IDF scores \n",
    "resulting_matrix = vectorizer.transform(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "    \n",
    "product_id = product_reviews_by_category[word2vec_prediction_str][\"product_id\"].tolist() \n",
    "    \n",
    "resulting_matrix = pd.DataFrame(resulting_matrix.toarray(), index=product_id, columns=vectorizer.get_feature_names_out()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0ef42fda-eee2-4ffc-9584-c9ce271116f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ac9d9e379c606e36a8094a6046f75dc\n"
     ]
    }
   ],
   "source": [
    "# determine product in category that's most similar to user input \n",
    "user_input_TF_IDF_vector = vectorizer.transform([user_input]) \n",
    "# similarity of user input word vector and each of the rows' word vectors \n",
    "similarity = cosine_similarity(user_input_TF_IDF_Vector, resulting_matrix) \n",
    "greatest_similarity_indices = np.argmax(similarity) \n",
    "\n",
    "# find index of the three row (if applicable) whose word vector shares the greatest \n",
    "# similarity with user input word vector \n",
    "#lowest_to_highest_similarity_indices = np.argsort(similarity) \n",
    "\n",
    "#if (len(lowest_to_highest_similarity_indices) == 3) | (len(lowest_to_highest_similarity_indices) > 3): \n",
    "#    greatest_similarity_indices = lowest_to_highest_similarity_indices[-3:] \n",
    "#    # sort the indices to be highest to lowest of the three \n",
    "#    #greatest_similarity_indices = greatest_similarity_indices[::-1] \n",
    "#elif len(lowest_to_highest_similarity_indices) == 2: \n",
    "#    greatest_similarity_indices = lowest_to_highest_similarity_indices[-2:]\n",
    "#    print(lowest_to_highest_similarity_indices[-2]) \n",
    "#    # sort the indices to be highest to lowest of the three \n",
    "#    #greatest_similarity_indices = greatest_similarity_indices[::-1] \n",
    "#elif len(lowest_to_highest_similarity_indices) == 1: \n",
    "#    greatest_similarity_indices = lowest_to_highest_similarity_indices[-1:] \n",
    "#else: \n",
    "#    greatest_similarity_indices = -1 \n",
    "# product_ids of the three rows whose word vector share the greatest simiilarity with user \n",
    "# input word vector \n",
    "\n",
    "#print(greatest_similarity_indices) \n",
    "greatest_similarity_product_ids = resulting_matrix.index[greatest_similarity_indices] \n",
    "print(greatest_similarity_product_ids) \n",
    "\n",
    "# out of the similar products, find the one with the highest rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "51d666a7-b4af-45fb-b740-eaa15cf46bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0  6684  6685 ...  3347  3340 10031]\n",
      "Index(['5ac9d9e379c606e36a8094a6046f75dc', 'e0cf79767c5b016251fe139915c59a26',\n",
      "       '0a9a9c25c5a06532d1766e00db833a7f', '2948658cb6abc82847412be7201bfc4c',\n",
      "       '921d31a1daa51460b7a95ea5f3ab64d5', '9ea1152d6d52dc57ab2ea49aa626adc1',\n",
      "       '67bd616e1ba0d3d3e8545f3113b0140d', '417e213344336988e562ccc3975987f4',\n",
      "       'cf2854dbad42c9f15b2e69add9bcb1a0', '719d571299707561c34ba04ab867b32a',\n",
      "       ...\n",
      "       '58e14150c9316b8f981742498dd97606', 'af91083bde899b201798b52ae89babea',\n",
      "       'cfd414b4463647f58c7775eaae06893d', '82fd0e5d33b58ad696f75449679c1470',\n",
      "       '76ad24d8518857df0f3dc45b2f5faf2d', 'adf591c625cb265c12bc6749d3a2f757',\n",
      "       '7b6669ccb9510397f7923a979c895733', '03552ec45033c8658713c541f6af9f05',\n",
      "       '4100a608bd0aa524b06ffefba973707b', '006619bbed68b000c8ba3f8725d5409e'],\n",
      "      dtype='object', length=10032)\n"
     ]
    }
   ],
   "source": [
    "# determine product in category that's most similar to user input \n",
    "user_input_TF_IDF_vector = vectorizer.transform([user_input]) \n",
    "# similarity of user input word vector and each of the rows' word vectors \n",
    "similarity = cosine_similarity(user_input_TF_IDF_vector, resulting_matrix) \n",
    "greatest_similarity_indices = np.argsort(similarity[0][::-1]) \n",
    "print(greatest_similarity_indices) \n",
    "greatest_similarity_product_ids = resulting_matrix.index[greatest_similarity_indices] \n",
    "print(greatest_similarity_product_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "97892399-89cd-4642-ae8f-695449f2fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How about this product\n",
      "Product:  5ac9d9e379c606e36a8094a6046f75dc\n",
      "Price:  109.9\n",
      "Average Product Rating:  1.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# rows with that product id \n",
    "products_df = df[df[\"product_id\"] == greatest_similarity_product_ids[0]] \n",
    "\n",
    "print(\"How about this product?\") \n",
    "print(\"Product: \", greatest_similarity_product_ids[0]) \n",
    "print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "873adcb7-f800-4eec-afc5-1eb0ab670170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want more detail about this product? (Y/N) n\n",
      "Would you like more similar product recommendations? (Y/N) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok. Here are some more product recommendations.\n",
      "Product:  5ac9d9e379c606e36a8094a6046f75dc\n",
      "Price:  29.9\n",
      "Average Product Rating:  4.474820143884892 \n",
      "\n",
      "Product:  5ac9d9e379c606e36a8094a6046f75dc\n",
      "Price:  29.9\n",
      "Average Product Rating:  4.474820143884892 \n",
      "\n",
      "Product:  5ac9d9e379c606e36a8094a6046f75dc\n",
      "Price:  14.99\n",
      "Average Product Rating:  3.933333333333333\n"
     ]
    }
   ],
   "source": [
    "more_detail_user_input = input(\"Do you want more detail about this product? (Y/N)\") \n",
    "\n",
    "more_detail_user_input = more_detail_user_input.upper().strip() \n",
    "\n",
    "more_recommendations = \"N\" \n",
    "more_detail = \"\" \n",
    "\n",
    "if more_detail_user_input == \"Y\": \n",
    "    print(\"Ok. Here is more detail about the product.\") \n",
    "    print(\"Total Orders: \", len(products_df)) \n",
    "    print(\"Product Weight (g): \", products_df[\"product_weight_g\"].iloc[0]) \n",
    "    print(\"Product Length (cm): \", products_df[\"product_length_cm\"].iloc[0]) \n",
    "    print(\"Product Height (cm): \", products_df[\"product_height_cm\"].iloc[0]) \n",
    "    print(\"Product Width (cm): \", products_df[\"product_width_cm\"].iloc[0]) \n",
    "else: \n",
    "    more_recommendations = input(\"Would you like more similar product recommendations? (Y/N)\") \n",
    "\n",
    "more_recommendations = more_recommendations.upper().strip() \n",
    "\n",
    "if more_recommendations == \"Y\": \n",
    "    print(\"Ok. Here are some more product recommendations.\") \n",
    "    if (len(greatest_similarity_product_ids) == 3) | (len(greatest_similarity_product_ids) > 3): \n",
    "        products_df = df[df[\"product_id\"] == greatest_similarity_product_ids[1]] \n",
    "    \n",
    "        print(\"Product: \", greatest_similarity_product_ids[0]) \n",
    "        print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "        print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "\n",
    "        products_df = df[df[\"product_id\"] == greatest_similarity_product_ids[1]] \n",
    "        print(\"Product: \", greatest_similarity_product_ids[0]) \n",
    "        print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "        print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "\n",
    "        products_df = df[df[\"product_id\"] == greatest_similarity_product_ids[2]] \n",
    "        print(\"Product: \", greatest_similarity_product_ids[0]) \n",
    "        print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "        print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "\n",
    "    elif len(greatest_similarity_product_ids) == 2: \n",
    "        products_df = df[df[\"product_id\"] == greatest_similarity_product_ids[1]] \n",
    "    \n",
    "        print(\"Product: \", greatest_similarity_product_ids[0]) \n",
    "        print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "        print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "\n",
    "        products_df = df[df[\"product_id\"] == greatest_similarity_product_ids[1]] \n",
    "        print(\"Product: \", greatest_similarity_product_ids[0]) \n",
    "        print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "        print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "\n",
    "    else: \n",
    "        more_detail = input(\"There are no more similar products. Please input more detail to get better product recommendations.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e941f605-7f53-4f9c-b4fe-e3fa948a5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommendation_quality = input(\"Was that a good recommendation? (Y/N)\") \n",
    "\n",
    "# recommend more related products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6db90482-e474-482f-b30a-54431a4d79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category prediction using TF-IDF? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0b9ef26-0d41-4ff3-908f-9ee5a65ca0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which category is the product in? Enter in number.\n",
      "1: housewares\n",
      "2: perfumery\n",
      "3: auto\n",
      "4: pet_shop\n",
      "5: stationery\n",
      "6: miscellaneous\n",
      "7: furniture_decor\n",
      "8: office_furniture\n",
      "9: garden_tools\n",
      "10: computers_accessories\n",
      "11: bed_bath_table\n",
      "12: toys\n",
      "13: construction_tools_construction\n",
      "14: telephony\n",
      "15: health_beauty\n",
      "16: electronics\n",
      "17: baby\n",
      "18: cool_stuff\n",
      "19: watches_gifts\n",
      "20: air_conditioning\n",
      "21: sports_leisure\n",
      "22: books_general_interest\n",
      "23: small_appliances\n",
      "24: food\n",
      "25: luggage_accessories\n",
      "26: fashion_underwear_beach\n",
      "27: christmas_supplies\n",
      "28: fashion_bags_accessories\n",
      "29: musical_instruments\n",
      "30: construction_tools_lights\n",
      "31: books_technical\n",
      "32: costruction_tools_garden\n",
      "33: home_appliances\n",
      "34: market_place\n",
      "35: agro_industry_and_commerce\n",
      "36: party_supplies\n",
      "37: home_confort\n",
      "38: cds_dvds_musicals\n",
      "39: industry_commerce_and_business\n",
      "40: consoles_games\n",
      "41: furniture_bedroom\n",
      "42: construction_tools_safety\n",
      "43: fixed_telephony\n",
      "44: drinks\n",
      "45: kitchen_dining_laundry_garden_furniture\n",
      "46: fashion_shoes\n",
      "47: home_construction\n",
      "48: audio\n",
      "49: home_appliances_2\n",
      "50: fashion_male_clothing\n",
      "51: cine_photo\n",
      "52: furniture_living_room\n",
      "53: art\n",
      "54: food_drink\n",
      "55: tablets_printing_image\n",
      "56: fashion_sport\n",
      "57: la_cuisine\n",
      "58: flowers\n",
      "59: computers\n",
      "60: home_comfort_2\n",
      "61: small_appliances_home_oven_and_coffee\n",
      "62: dvds_blu_ray\n",
      "63: costruction_tools_tools\n",
      "64: fashio_female_clothing\n",
      "65: furniture_mattress_and_upholstery\n",
      "66: signaling_and_security\n",
      "67: diapers_and_hygiene\n",
      "68: books_imported\n",
      "69: fashion_childrens_clothes\n",
      "70: music\n",
      "71: arts_and_craftmanship\n",
      "72: security_and_services\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    }
   ],
   "source": [
    "# a dictionary with a number associated with each product category \n",
    "product_categories_dict = {} \n",
    "\n",
    "# array with unique product categories \n",
    "product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "\n",
    "for i in range(len(product_categories)): \n",
    "    product_categories_dict[i+1] = product_categories[i] \n",
    "\n",
    "# ask user for product category \n",
    "print(\"Which category is the product in? Enter in number.\") \n",
    "for keys, values in product_categories_dict.items(): \n",
    "    print(f\"{keys}: {values}\") \n",
    "\n",
    "user_input_2 = input(\"\") \n",
    "\n",
    "user_input_2 = int(user_input_2.strip()) \n",
    "\n",
    "user_input_product_cat = product_categories_dict.get(user_input_2) \n",
    "\n",
    "#print(resulting_matrices[\"housewares\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b2d82-7602-4f5a-afe1-1daba052f931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
