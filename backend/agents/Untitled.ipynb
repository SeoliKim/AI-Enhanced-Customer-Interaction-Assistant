{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74e1704-b3d6-43ac-bd49-786b70e8d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Found existing installation: numpy 1.26.0\n",
      "Uninstalling numpy-1.26.0:\n",
      "  Successfully uninstalled numpy-1.26.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.0\n",
      "  Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (53 kB)\n",
      "Using cached numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/jocelyn/miniconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tableone 0.9.1 requires openpyxl>=3.1.2, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n",
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --yes\n",
      "Requirement already satisfied: gensim in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /Users/jocelyn/miniconda3/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "!pip install scikit-learn \n",
    "!pip uninstall numpy --yes \n",
    "!pip install numpy==1.26.0 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score \n",
    "!pip install gensim --yes \n",
    "!pip install gensim \n",
    "import gensim \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import time \n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c162ee-fb74-4e4d-9ad0-e7ec9db1fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/jocelyn/Desktop/DXC-4 Technology /AI-Enhanced-Customer-Interaction-Assistant/data/Final_db.csv\" \n",
    "df = pd.read_csv(filename, header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b74fa9-81e3-4762-9da8-513c07e7c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-1.17839493e-01,  3.51078838e-01, -1.09222129e-01, -9.62413326e-02,\n",
      "       -2.76064035e-02, -6.80157781e-01,  1.35842443e-01,  1.21840560e+00,\n",
      "       -9.07851875e-01, -8.32121253e-01, -1.92473561e-01, -2.77980626e-01,\n",
      "        3.22720498e-01, -2.77178492e-02,  8.01469311e-02, -2.95261115e-01,\n",
      "        4.24920261e-01, -2.99648464e-01, -2.45427221e-01, -7.70067692e-01,\n",
      "        1.65753901e-01, -4.58791912e-01,  5.26299417e-01, -8.81777145e-03,\n",
      "       -3.69859397e-01,  3.91988128e-01, -5.63695490e-01, -4.86627162e-01,\n",
      "       -3.39859277e-01,  2.87662059e-01,  2.91922420e-01,  4.95757870e-02,\n",
      "       -5.02585284e-02, -5.35770655e-01, -1.93634972e-01,  2.78314769e-01,\n",
      "       -3.35827023e-01, -1.38966054e-01,  5.72209656e-02, -1.18308067e+00,\n",
      "       -5.01151085e-02, -1.96180016e-01,  5.76032519e-01, -7.04499930e-02,\n",
      "        3.40741694e-01, -2.26590112e-01,  3.50452751e-01, -4.81269807e-02,\n",
      "        7.82623172e-01,  3.64676267e-01, -1.74196418e-02,  3.24247152e-01,\n",
      "       -5.61258852e-01, -3.95898461e-01, -2.43495256e-01,  1.73331767e-01,\n",
      "        1.41201332e-01,  9.59074572e-02, -6.39497042e-01, -8.83545876e-02,\n",
      "        1.12307645e-01,  3.75513434e-01,  1.75213844e-01,  6.85492516e-01,\n",
      "       -5.02384380e-02,  7.32064009e-01,  2.57285744e-01,  6.05107844e-01,\n",
      "       -7.77267277e-01,  1.59627780e-01,  1.10569775e-01,  6.13420367e-01,\n",
      "        4.52283621e-01,  1.51418447e-01,  6.70786500e-01, -4.27226871e-01,\n",
      "        7.17788469e-04,  3.38772804e-01,  3.55730355e-01, -1.49704916e-02,\n",
      "       -2.80893259e-02, -1.67725384e-01, -4.13464785e-01,  2.00996906e-01,\n",
      "       -3.95378202e-01, -6.94951653e-01,  2.48106048e-01,  7.75281131e-01,\n",
      "        4.49450910e-01,  6.18849620e-02,  1.32149130e-01,  4.50986922e-01,\n",
      "        7.01721162e-02, -1.87664464e-01,  5.43779612e-01, -1.16948344e-01,\n",
      "       -8.69531929e-02, -3.99292976e-01,  1.39130846e-01, -2.19150931e-01],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.4310716 ,  0.16546318, -0.33358783, -0.35876882,  0.17521778,\n",
      "       -0.41369087, -0.20422138,  0.5449396 , -0.27405226,  0.47657275,\n",
      "       -0.11299497, -0.7093364 ,  0.31954134,  0.38101247,  0.38773283,\n",
      "       -0.7265494 ,  0.03731336, -0.33249336,  0.41763344, -0.6219504 ,\n",
      "       -0.12919724,  0.03645619,  0.07327253, -0.3545633 , -0.40540195,\n",
      "        0.9702822 , -0.11049218, -0.8004507 , -0.41494277,  0.03300848,\n",
      "        0.5981779 ,  0.08520042,  0.795345  , -0.15566841, -0.29668242,\n",
      "        0.349253  ,  0.30245614, -0.46803725, -0.33596677, -1.039289  ,\n",
      "        0.01954657, -0.81421244, -0.3088109 ,  0.3441379 , -0.10066667,\n",
      "       -0.53593326, -0.32731518, -0.12600367,  0.15069696, -0.34851068,\n",
      "        0.2885598 , -0.31780502,  0.3146263 ,  0.19510752,  0.09293354,\n",
      "        0.09432247, -0.26915014, -0.09645628, -0.591242  ,  0.26310322,\n",
      "        0.47462386, -0.4269139 ,  0.01611663,  0.60751736, -0.6249553 ,\n",
      "        0.33908302, -0.20828125, -0.26621383, -0.9786791 ,  0.77132595,\n",
      "       -0.93794656,  0.35261402,  0.82357544, -0.71435916,  0.10957952,\n",
      "        0.51497036, -0.38261473,  0.3014595 , -0.675096  , -0.03193021,\n",
      "        0.03614877,  0.33493304, -0.9667463 ,  0.44750664, -0.3864407 ,\n",
      "        0.08113632,  0.17009619,  1.131775  , -0.05598931, -0.16915824,\n",
      "        0.73374355,  0.02614603,  0.3905428 ,  0.43468636,  0.64627445,\n",
      "        0.0586126 , -0.17858404,  0.0520502 ,  0.40835527, -0.04661986],\n",
      "      dtype=float32), array([-0.4997542 ,  0.3282001 , -0.03112036, -0.01250895,  0.251182  ,\n",
      "       -0.86907154,  0.28556028,  0.5389777 , -0.50750893,  0.09128747,\n",
      "        0.09553742,  0.09913814,  0.4841024 , -0.06873307,  0.599948  ,\n",
      "       -0.26696545,  0.7479072 , -0.35580003, -0.36801997, -1.784949  ,\n",
      "        0.58122855, -0.12001663,  0.88831997, -0.01507519, -0.54805684,\n",
      "        0.48651564, -0.23092063, -0.25065446, -0.2921835 ,  0.4637628 ,\n",
      "        0.91056365,  0.53326005,  0.26638103, -0.36714733, -0.24882454,\n",
      "        0.77389115, -0.20441747, -0.49516836, -0.7164306 , -0.7241528 ,\n",
      "        0.46749517, -0.4971687 ,  0.89590526,  0.2638947 ,  0.5199847 ,\n",
      "       -0.01564232, -0.15903723, -0.3327448 ,  0.50897354, -0.1118767 ,\n",
      "        0.93696755, -0.51955384, -0.3597746 , -0.0565819 , -0.8287294 ,\n",
      "       -0.32047677, -0.34202734,  0.2557199 , -0.6449519 ,  0.16984038,\n",
      "        0.12581308,  0.18669079,  0.57880527,  0.04288292, -0.09054155,\n",
      "        0.37902918,  0.24278885,  0.8470862 , -0.87991863,  0.13267028,\n",
      "       -0.26734102,  0.45232752,  0.1315374 ,  0.5726585 ,  1.2457124 ,\n",
      "        0.16819145,  0.07866877,  0.939174  , -0.5818088 ,  0.27108264,\n",
      "       -0.11358798,  0.40060404, -0.7234743 ,  0.6551985 ,  0.03531583,\n",
      "       -0.32678735,  0.4646503 ,  1.0048145 ,  0.02983527, -0.33481   ,\n",
      "        1.2149239 ,  0.30133232,  0.09228168,  0.249552  ,  0.34244505,\n",
      "       -0.18526804,  0.7235084 , -0.41602004, -0.6355274 ,  0.26782602],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([-0.74241596,  0.44993627,  0.01443075,  0.6458789 , -0.3352523 ,\n",
      "       -0.4779284 , -0.25160658,  1.4825424 , -0.72995025, -0.85018605,\n",
      "       -0.16577022, -0.87369704,  0.00946115,  0.26451758,  0.2916799 ,\n",
      "       -0.36182487,  0.6229077 , -0.49756777,  0.38603708, -1.1879357 ,\n",
      "       -0.47238317, -0.06674704, -0.02025491, -0.0995319 , -0.5048976 ,\n",
      "       -0.89717394, -0.91777974, -0.4351202 , -0.35705984,  0.29219696,\n",
      "        0.6601551 , -0.13659482, -0.9851826 , -0.0961649 , -0.23281474,\n",
      "        0.28478855,  0.01970655, -0.01254549,  0.28087494, -0.4553361 ,\n",
      "        0.2662576 , -0.10044365, -0.47817278, -0.24375586,  0.71630925,\n",
      "        0.23046042,  0.4263916 ,  0.16149943,  0.8637466 ,  0.33546016,\n",
      "        0.12188496, -0.27687725, -0.3857553 ,  0.44785145,  0.20317908,\n",
      "        1.0231606 ,  0.7741213 ,  0.10150105, -0.5295095 ,  0.41525117,\n",
      "       -0.5063309 ,  1.0392982 , -0.5404639 , -0.4777491 ,  0.2176265 ,\n",
      "       -0.60754985, -0.02248628,  0.0475173 , -1.064545  , -0.08524666,\n",
      "        0.51585835,  0.61740273,  0.98370177,  0.2437225 ,  0.5838023 ,\n",
      "       -0.01033361, -0.13519527, -0.44740543, -0.448956  , -0.08071976,\n",
      "       -0.25336012, -0.8077667 ,  0.1571828 ,  0.8412936 , -0.29846215,\n",
      "       -0.3027092 , -0.538306  ,  1.2635033 ,  0.9928904 ,  1.0210266 ,\n",
      "        0.56438416,  0.8169549 , -0.28973344,  0.97097826,  0.60064936,\n",
      "        0.8563033 ,  0.15354633,  0.14116594,  0.13274406, -0.26815787],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# check to see if there are products with multiple orders \n",
    "product_id_value_counts = df[\"product_id\"].value_counts() \n",
    "\n",
    "# store the products with multiple orders in products_multiple_orders \n",
    "products_multiple_orders = product_id_value_counts[product_id_value_counts > 1] \n",
    "\n",
    "# create a new column in df that stores the number of times each item was purchased \n",
    "df[\"times_purchased\"] = df[\"product_id\"].map(product_id_value_counts) \n",
    "\n",
    "# stores all of the unique product categories into the array \"product_categories\" \n",
    "product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "\n",
    "# fill in rows in df[\"review_comment_title\"] column that have na values with \"\" \n",
    "df[\"review_comment_title\"] = df[\"review_comment_title\"].fillna(\"\") \n",
    "\n",
    "# fill in rows in df[\"review_comment_message\"] column that have na values with \"\" \n",
    "df[\"review_comment_message\"] = df[\"review_comment_message\"].fillna(\"\") \n",
    "\n",
    "# merge the product reviews and product review titles with a space in between both \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"review_comment_message\"] + \" \" + df[\"review_comment_title\"] \n",
    "df[\"merged_review_messages_and_titles\"] = df[\"merged_review_messages_and_titles\"].str.strip() \n",
    "\n",
    "# dictionary to store dataframes of the product reviews for all products in each category \n",
    "# products are separated by category \n",
    "product_reviews_by_category = {}; \n",
    "\n",
    "# fill in dictionary with keys (df category) and values (product_id and product reviews for all products in that category) \n",
    "for category in product_categories: \n",
    "    product_reviews_by_category[\"df_\" + str(category)] = df[df[\"product_cat_name_translated\"] == category][[\"product_id\", \"merged_review_messages_and_titles\"]] \n",
    "\n",
    "# feature ~ product title and review \n",
    "X = df[\"merged_review_messages_and_titles\"] \n",
    "\n",
    "# label ~ product category \n",
    "y = df[\"product_cat_name_translated\"] \n",
    "\n",
    "# preprocess each (each row) product title and review \n",
    "X = X.apply(lambda row: gensim.utils.simple_preprocess(row)) \n",
    "\n",
    "# split data into a training set and a test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=1111) \n",
    "\n",
    "word2vec_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5, min_count=1) \n",
    "\n",
    "# replace every word in the dataset that's also found in word2vec_model with their word embedding \n",
    "# a set with all of the unique words in the word2vex_model \n",
    "words = set(word2vec_model.wv.index_to_key) \n",
    "\n",
    "# X_train word embeddings \n",
    "# array for all of the word embeddings for X_train \n",
    "X_train_word_embeddings = []; \n",
    "for row in X_train: \n",
    "    row_embedding = [] \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_train_word_embeddings.append(np.array(row_embedding)) \n",
    "\n",
    "# X_test word embeddings \n",
    "# array for all of the word embeddings for X_test \n",
    "X_test_word_embeddings = []; \n",
    "for row in X_test: \n",
    "    row_embedding = []; \n",
    "    for word in words: \n",
    "        if word in row: \n",
    "            row_embedding.append(word2vec_model.wv[word]) \n",
    "    X_test_word_embeddings.append(np.array(row_embedding)) \n",
    "\n",
    "X_train_feature_vector = []\n",
    "for w in X_train_word_embeddings:\n",
    "    if w.size:\n",
    "        X_train_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_train_feature_vector.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_feature_vector = []\n",
    "for w in X_test_word_embeddings:\n",
    "    if w.size:\n",
    "        X_test_feature_vector.append(w.mean(axis=0))\n",
    "    else:\n",
    "        X_test_feature_vector.append(np.zeros(100, dtype=float))\n",
    "\n",
    "print(X_train_feature_vector[1:11]) \n",
    "\n",
    "# logistic regression \n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_feature_vector, y_train)\n",
    "\n",
    "probability_predictions = model.predict_proba(X_test_feature_vector) \n",
    "\n",
    "# predict most likely product category \n",
    "class_label_predictions = model.predict(X_test_feature_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e5afc-e195-43e3-b75d-5adbe7f91904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome to the personalized product recommendation chatbot.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "What product are you looking for? saber\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello! Welcome to the personalized product recommendation chatbot.\") \n",
    "\n",
    "# create a list containing the vectors for the tokens/words found in the user input that are also found in the dataset of available products \n",
    "token_vectors = [] \n",
    "\n",
    "while len(token_vectors) == 0: \n",
    "    another = \"\"\n",
    "    user_input = input(\"\\nWhat product are you looking for?\") \n",
    "\n",
    "    print(\"Generating response ...\") \n",
    "\n",
    "    user_input_tokens = list(gensim.utils.simple_preprocess(user_input)) \n",
    "    token_vectors = [] \n",
    "    \n",
    "    # loop through all tokens from the tokenized version of the user input \n",
    "    for token in user_input_tokens: \n",
    "        # if the token is also found in the dataset \n",
    "        if token in word2vec_model.wv.key_to_index: \n",
    "            # add its word vector to the \"token_vectors\" list \n",
    "            token_vectors.append(word2vec_model.wv[token]) \n",
    "\n",
    "    # if there are vectors \n",
    "    if len(token_vectors) > 0: \n",
    "        # calculate the mean for each token_vector and combine into an array \n",
    "        overall_token_vector = np.mean(token_vectors, axis=0) \n",
    "        # reshape into a two dimensional array \n",
    "        overall_token_vector = overall_token_vector.reshape(1, -1) \n",
    "        word2vec_prediction = model.predict(overall_token_vector) \n",
    "    \n",
    "    else: \n",
    "        user_input = input(\"\\nWe can't find a related product. Please input more detail.\") \n",
    "\n",
    "    word2vec_prediction_str = \"df_\" + str(word2vec_prediction[0]) \n",
    "    \n",
    "    #vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "    \n",
    "    product_reviews_by_category[word2vec_prediction_str] \n",
    "    \n",
    "    # use bigrams (for cases of negation like \"not good\") and trigrams (for cases with numbers like \"bought 3 pairs\") \n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2, 3)) \n",
    "    \n",
    "    # fit vectorizer to the product review titles and messages \n",
    "    vectorizer.fit(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "    \n",
    "    # result_matrix contains each document's TF_IDF scores \n",
    "    resulting_matrix = vectorizer.transform(product_reviews_by_category[word2vec_prediction_str][\"merged_review_messages_and_titles\"]) \n",
    "        \n",
    "    product_id = product_reviews_by_category[word2vec_prediction_str][\"product_id\"].tolist() \n",
    "        \n",
    "    resulting_matrix = pd.DataFrame(resulting_matrix.toarray(), index=product_id, columns=vectorizer.get_feature_names_out()) \n",
    "    \n",
    "    # determine product in category that's most similar to user input \n",
    "    user_input_TF_IDF_vector = vectorizer.transform([user_input]) \n",
    "    # similarity of user input word vector and each of the rows' word vectors \n",
    "    similarity = cosine_similarity(user_input_TF_IDF_vector, resulting_matrix) \n",
    "    greatest_similarity_indices = np.argsort(similarity[0][::-1]) \n",
    "    greatest_similarity_product_ids = resulting_matrix.index[greatest_similarity_indices] \n",
    "    greatest_similarity_product_ids_list = greatest_similarity_product_ids.unique().tolist() \n",
    "    \n",
    "    # rows with that product id \n",
    "    products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[0]] \n",
    "    \n",
    "    clear_output(wait=True) \n",
    "    \n",
    "    print(\"\\nHow about this product?\") \n",
    "    print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "    print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "    print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "    more_detail_user_input = input(\"\\nDo you want more detail about this product? (Y/N)\") \n",
    "    \n",
    "    more_detail_user_input = more_detail_user_input.upper().strip() \n",
    "    \n",
    "    more_recommendations = \"N\" \n",
    "    more_detail = \"\" \n",
    "    moree = False \n",
    "    user_input_product_cat = \"\" \n",
    "    user_input = \"\" \n",
    "    \n",
    "    if more_detail_user_input == \"Y\": \n",
    "        print(\"\\nOk. Here is more detail about the product.\") \n",
    "        print(\"Total Orders: \", len(products_df)) \n",
    "        print(\"Product Weight (g): \", products_df[\"product_weight_g\"].iloc[0]) \n",
    "        print(\"Product Length (cm): \", products_df[\"product_length_cm\"].iloc[0]) \n",
    "        print(\"Product Height (cm): \", products_df[\"product_height_cm\"].iloc[0]) \n",
    "        print(\"Product Width (cm): \", products_df[\"product_width_cm\"].iloc[0]) \n",
    "        \n",
    "        good = input(\"\\nIs this a good recommendation? (Y/N)\") \n",
    "        good = good.upper().strip() \n",
    "    \n",
    "        if good == \"Y\": \n",
    "            another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "            another = another.upper().strip() \n",
    "            \n",
    "            if another == \"Y\": \n",
    "                token_vectors = []; \n",
    "            else: \n",
    "                print(\"\\nHave a great day! :)\") \n",
    "                break \n",
    "        \n",
    "        else: \n",
    "            print(\"\\nWe're sorry.\") \n",
    "            token_vectors = []; \n",
    "    \n",
    "    else: \n",
    "        more_recommendations = input(\"\\nWould you like more similar product recommendations? (Y/N)\") \n",
    "        more_recommendations = more_recommendations.upper().strip() \n",
    "    \n",
    "    if more_recommendations == \"Y\": \n",
    "        print(\"\\nOk. Here are some more product recommendations.\") \n",
    "        if (len(greatest_similarity_product_ids_list) == 3) | (len(greatest_similarity_product_ids_list) > 3): \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "        \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[2]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "            good = input(\"\\nWere any of these recommendations helpful? (Y/N)\") \n",
    "            good = good.upper().strip() \n",
    "    \n",
    "            if good == \"Y\": \n",
    "                another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "                another = another.upper().strip() \n",
    "                \n",
    "                if another == \"Y\": \n",
    "                    token_vectors = []; \n",
    "                else: \n",
    "                    print(\"\\nHave a great day! :)\") \n",
    "                    break \n",
    "            \n",
    "            else: \n",
    "                token_vectors = []; \n",
    "                print(\"\\nWe're sorry.\") \n",
    "    \n",
    "        elif len(greatest_similarity_product_ids_list) == 2: \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "        \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean(), \"\\n\") \n",
    "    \n",
    "            products_df = df[df[\"product_id\"] == greatest_similarity_product_ids_list[1]] \n",
    "            print(\"Product: \", greatest_similarity_product_ids_list[0]) \n",
    "            print(\"Price: \", products_df[\"price\"].iloc[0]) \n",
    "            print(\"Average Product Rating: \", products_df[\"review_score\"].mean()) \n",
    "    \n",
    "            good = input(\"\\nWere any of these recommendations helpful? (Y/N)\") \n",
    "            good = good.upper().strip() \n",
    "    \n",
    "            if good == \"Y\": \n",
    "                another = input(\"\\nWe're glad! Would you like like help finding another product? (Y/N)\") \n",
    "                another = another.upper().strip() \n",
    "                \n",
    "                if another == \"Y\": \n",
    "                    token_vectors = []; \n",
    "                else: \n",
    "                    print(\"\\nHave a great day! :)\") \n",
    "                    break \n",
    "            \n",
    "            else: \n",
    "                token_vectors = []; \n",
    "                print(\"\\nWe're sorry.\") \n",
    "    \n",
    "        else: \n",
    "            moree = True \n",
    "            \n",
    "            more_detail = input(\"\\nThere are no more similar products. What category is your product in? Enter number.\") \n",
    "    \n",
    "            # a dictionary with a number associated with each product category \n",
    "            product_categories_dict = {} \n",
    "        \n",
    "            # array with unique product categories \n",
    "            product_categories = df[\"product_cat_name_translated\"].unique() \n",
    "        \n",
    "            for i in range(len(product_categories)): \n",
    "                product_categories_dict[i+1] = product_categories[i] \n",
    "        \n",
    "            # ask user for product category \n",
    "            print(\"\\nWhich category is the product in? Enter in number.\") \n",
    "            for keys, values in product_categories_dict.items(): \n",
    "                print(f\"{keys}: {values}\") \n",
    "            \n",
    "            user_input_2 = input(\"\") \n",
    "            \n",
    "            user_input_2 = int(user_input_2.strip()) \n",
    "            \n",
    "            user_input_product_cat = product_categories_dict.get(user_input_2) \n",
    "\n",
    "    else: \n",
    "        if (more_detail_user_input != \"Y\") & (another != \"Y\"): \n",
    "            print(\"\\nHave a great day! :)\") \n",
    "            break \n",
    "    \n",
    "    if moree == True: \n",
    "        user_product_category = df[df[\"product_cat_name_translated\"] == user_input_product_cat] \n",
    "        ranked_products = user_product_category.sort_values(by=\"review_score\", ascending=False) \n",
    "        \n",
    "        print(\"\\nHere are the three highest ranked products in that category.\") \n",
    "        print(ranked_products.head(3)[\"product_id\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8822c3-8499-4d0d-82ac-8ac9b9bf5f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
